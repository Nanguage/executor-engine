{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Executor Engine \ud83d\ude80  <p> Effortless, flexible, and powerful job execution engine. </p> <p> </p> <p>Executor Engine \ud83d\ude80 is a powerful and versatile package designed for managing and streamlining job execution across various platforms. With support for multiple job types, including <code>LocalJob</code>, <code>ThreadJob</code>, <code>ProcessJob</code>, <code>DaskJob</code>, and more, Executor Engine provides flexibility and adaptability for a wide range of tasks. The package also offers extensible job types, such as <code>SubprocessJob</code> and <code>WebappJob</code>, ensuring that your workflow can be easily customized to meet specific requirements.</p> <p>By harnessing the capabilities of Executor Engine, users can effortlessly construct parallel workflows to optimize their processing pipeline. The engine facilitates conditional job execution, allowing for the configuration of conditions such as <code>AfterAnother</code>, <code>AfterTimepoint</code>, and more. This level of customization simplifies the creation of complex, parallel workflows and maximizes efficiency.</p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>\ud83d\udcda Support multiple job types<ul> <li><code>LocalJob</code>, <code>ThreadJob</code>, <code>ProcessJob</code>, <code>DaskJob</code></li> <li>Extend job types: <code>SubprocessJob</code>, <code>WebappJob</code></li> </ul> </li> <li>\ud83d\udd27 Job management<ul> <li>Job dependency management.</li> <li>Job status: Pending, Running, Done, Failed, Cancelled.</li> <li>Limit the number of concurrent jobs.</li> <li>Status management: Cancel, Re-run, ...</li> <li>Auto retry on failure.</li> <li>Serilization and deserialization.</li> </ul> </li> <li>\u23f1\ufe0f Conditional job execution.<ul> <li><code>AfterAnother</code>, <code>AfterOthers</code>: After another job or jobs done/failed/cancelled.</li> <li><code>AfterTimepoint</code>: After a time point.</li> <li>Condition combination:<ul> <li><code>AllSatisfied</code>: All conditions are met.</li> <li><code>AnySatisfied</code>: Any condition is met.</li> </ul> </li> <li>Allow user to define custom condition.</li> </ul> </li> <li>\ud83d\ude80 The launcher API for create parallel workflow in an easy way.</li> <li>\u26a1 Provide async and sync API, fully compatible with asyncio.</li> <li>\ud83c\udfaf 100% test coverage.</li> </ul>"},{"location":"#related-projects","title":"\ud83d\udd17 Related Projects","text":"<ul> <li>executor-http: HTTP server and client for executor engine.</li> <li>executor-view: Web interface for executor HTTP server.</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install executor-engine\n</code></pre> <p>With dask support:</p> <pre><code>pip install \"executor-engine[dask]\"\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic usage","text":"<p><code>Engine</code> is the core object of executor-engine. It manages the job execution. You can create an <code>Engine</code> object and submit jobs to it, then wait for the jobs to finish:</p> <pre><code>from executor.engine import Engine, LocalJob, ThreadJob, ProcessJob\n\ndef add(a, b):\n    return a + b\n\nwith Engine() as engine:\n    job1 = LocalJob(add, args=(1, 2))\n    job2 = ThreadJob(add, args=(job1.future, 4))\n    job3 = ProcessJob(add, args=(job2.future, 5))\n    engine.submit(job1, job2, job3)\n    engine.wait()  # wait all job finished\n    print(job1.result())  # 3\n    print(job2.result())  # 7\n    print(job3.result())  # 12\n</code></pre> <p>Use with asyncio:</p> <pre><code>from executor.engine import Engine, ProcessJob\nimport asyncio\n\nengine = Engine()\n\ndef add(a, b):\n    return a + b\n\nasync def add_async(a, b):\n    # async function can also be used as the job function\n    await asyncio.sleep(1.0)\n    return a + b\n\nasync def main():\n    job1 = ProcessJob(add_async, args=(1, 2))\n    job2 = ProcessJob(add, args=(job1.future, 4))\n    await engine.submit_async(job1, job2)\n    await engine.join()\n    print(job1.result())  # 3\n    print(job2.result())  # 7\n\nasyncio.run(main())\n# or just `await main()` in jupyter environment\n</code></pre>"},{"location":"getting-started/#job","title":"Job","text":"<p>Job is the basic unit of executor-engine. It represents a task to be executed.</p>"},{"location":"getting-started/#job-status","title":"Job status","text":"<p>Job has 6 status: <code>created</code>, <code>pending</code>, <code>running</code>, <code>done</code>, <code>failed</code>, <code>cancelled</code>.</p> <p>Here is the state transition diagram of job:</p> <pre><code>graph LR\n    created --&gt;|engine.submit| pending\n    pending --&gt;|runnable?| running\n    running --&gt;|Success| done\n    running --&gt;|Fail| failed\n    running --&gt;|Cancel| cancelled\n    done --&gt;|rerun| pending\n    failed --&gt;|rerun| pending\n    cancelled --&gt;|rerun| pending</code></pre>"},{"location":"getting-started/#job-types","title":"Job types","text":"<p>Executor engine provides 4 builtin job types: <code>LocalJob</code>,  <code>ThreadJob</code>,  <code>ProcessJob</code>,  <code>DaskJob</code></p> <p>They are executed by different backends and suitable for different scenarios.</p> Job type Backend Suitable for <code>LocalJob</code> <code>executor.engine.backend.local</code> Local function call <code>ThreadJob</code> <code>executor.engine.backend.thread</code> IO-bound tasks <code>ProcessJob</code> <code>executor.engine.backend.process</code> CPU-bound tasks <code>DaskJob</code> <code>executor.engine.backend.dask</code> Distributed tasks"},{"location":"getting-started/#conditional-job-execution","title":"Conditional job execution","text":"<p>After another job:</p> <pre><code>from executor.engine import Engine, ProcessJob\nfrom executor.engine.job.condition import AfterAnother\n\ndef add(a, b):\n    print(f\"add({a}, {b})\")\n    return a + b\n\nwith Engine() as engine:\n    job1 = ProcessJob(add, args=(1, 2))\n    job2 = ProcessJob(add, args=(3, 4), condition=AfterAnother(job_id=job1.id))\n    engine.submit(job1, job2)\n    # job2 will be executed after job1 finished\n    engine.wait()\n</code></pre> <p>After other jobs:</p> <pre><code>from executor.engine import Engine, ProcessJob\nfrom executor.engine.job.condition import AfterOthers\n\ndef add(a, b):\n    print(f\"add({a}, {b})\")\n    return a + b\n\nwith Engine() as engine:\n    job1 = ProcessJob(add, args=(1, 2))\n    job2 = ProcessJob(add, args=(3, 4))\n    job3 = ProcessJob(add, args=(5, 6), condition=AfterOthers(job_ids=[job1.id, job2.id]))\n    engine.submit(job3, job2, job1)\n    # job3 will be executed after job1 and job2 finished\n    engine.wait()\n</code></pre> <p>After a time point:</p> <pre><code>from executor.engine import Engine, ProcessJob\nfrom executor.engine.job.condition import AfterTimepoint\nfrom datetime import datetime, timedelta\n\ndef print_hello():\n    print(\"Hello\")\n\nwith Engine() as engine:\n    now = datetime.now()\n    after_5_seconds = now + timedelta(seconds=5)\n    job = ProcessJob(\n        print_hello,\n        condition=AfterTimepoint(timepoint=after_5_seconds))\n    # will print \"Hello\" after 5 seconds\n    engine.submit(job)\n    engine.wait()\n</code></pre> <p>See Condition for more details.</p>"},{"location":"getting-started/#condition-combination","title":"Condition combination","text":"<p><code>AllSatisfied</code> is used to combine multiple conditions, all conditions must be satisfied to execute the job:</p> <pre><code>from executor.engine import Engine, ThreadJob\nfrom executor.engine.job.condition import AllSatisfied, AfterAnother\n\ns = set()\n\njob1 = ThreadJob(lambda: s.add(1))\njob2 = ThreadJob(lambda: s.add(2))\n\ndef has_two_elements():\n    assert len(s) == 2\n\njob3 = ThreadJob(has_two_elements, condition=AllSatisfied(conditions=[\n    AfterAnother(job_id=job1.id),\n    AfterAnother(job_id=job2.id)\n]))\n\nwith Engine() as engine:\n    engine.submit(job3, job2, job1)\n    engine.wait()\n</code></pre> <p>Info</p> <p>When specify the job dependencies using the <code>JobFuture</code> like <code>job2 = ProcessJob(add, args=(1, job1.future))</code>. Executor engine will automatically inject a <code>AllSatisfied([job2.condition, AfterOthers([job1.id])])</code> condition to the job <code>job2</code>.</p> <p>Similarly, <code>AnySatisfied</code> is used to combine multiple conditions, any condition is satisfied to execute the job:</p> <pre><code>from executor.engine import Engine, ThreadJob\nfrom executor.engine.job.condition import AnySatisfied, AfterAnother\nimport time\n\ns = set()\n\ndef sleep_1s_and_add_1():\n    time.sleep(1.0)\n    s.add(1)\n\ndef has_one_element():\n    # when job3 is executed, only job1 is finished\n    assert len(s) == 1\n\nwith Engine() as engine:\n    job1 = ThreadJob(lambda: s.add(1))\n    job2 = ThreadJob(sleep_1s_and_add_1)\n    job3 = ThreadJob(has_one_element, condition=AnySatisfied(conditions=[\n        AfterAnother(job_id=job1.id),\n        AfterAnother(job_id=job2.id)\n    ]))\n    engine.submit(job3, job2, job1)\n    engine.wait()\n</code></pre>"},{"location":"getting-started/#syntactic-sugar-for-condition-combination","title":"Syntactic sugar for condition combination","text":"<p>You can use <code>&amp;</code> and <code>|</code> to combine conditions:</p> <pre><code>from executor.engine import Engine, ThreadJob\nfrom executor.engine.job.condition import AfterAnother\nimport time\n\ns = set()\n\ndef sleep_and_add_1(t: int):\n    time.sleep(t)\n    s.add(t)\n\ndef has_two_elements():\n    print(s)\n    assert len(s) == 2\n\nwith Engine() as engine:\n    job1 = ThreadJob(sleep_and_add_1, args=(1,))\n    job2 = ThreadJob(sleep_and_add_1, args=(2,))\n    job3 = ThreadJob(sleep_and_add_1, args=(3,))\n    job4 = ThreadJob(\n        has_two_elements,\n        condition=(\n            (\n                AfterAnother(job_id=job1.id) &amp;\n                AfterAnother(job_id=job2.id)\n            ) |\n            AfterAnother(job_id=job3.id)\n        )\n    )\n    engine.submit(job4, job3, job2, job1)\n    engine.wait()\n</code></pre>"},{"location":"getting-started/#custom-condition","title":"Custom condition","text":"<p>You can also define your own condition by inheriting <code>Condition</code> class:</p> <pre><code>from executor.engine import Engine, ThreadJob\nfrom executor.engine.job.condition import Condition\nimport random\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass RandomCondition(Condition):\n    probability: float = 0.5\n\n    def satisfy(self, engine: \"Engine\") -&gt; bool:\n        p = random.random()\n        print(f\"p={p}\")\n        if p &lt;= self.probability:\n            return True\n        else:\n            return False\n\n\nwith Engine() as engine:\n    job = ThreadJob(\n        lambda: print(\"hi\"),\n        condition=RandomCondition(0.2),\n        wait_time_delta=0.5)\n    # job has a 20% chance to be executed at each 0.5 seconds\n    engine.submit(job)\n    engine.wait()\n</code></pre>"},{"location":"getting-started/#extend-job-types","title":"Extend job types","text":"<p>There are 4 extend job types: <code>SubprocessJob</code>, <code>WebappJob</code> <code>SentinelJob</code> <code>CronJob</code></p> <p>They are used to execute shell commands, launch web applications and schedule jobs based on time.  The extend job types can based on the job types above(<code>LocalJob</code>, <code>ThreadJob</code>, <code>ProcessJob</code>, <code>DaskJob</code>).</p>"},{"location":"getting-started/#subprocessjob","title":"SubprocessJob","text":"<p><code>SubprocessJob</code> is a job type for executing shell commands. <code>SubprocessJob</code> accept a shell command as its argument. It will execute the command in a subprocess:</p> <pre><code>from executor.engine import Engine\nfrom executor.engine.job.extend import SubprocessJob\n\njob = SubprocessJob(\n    \"python -c 'print(1 + 2)'\",\n)\n\nwith Engine() as engine:\n    engine.submit(job)\n    engine.wait_job(job)\n</code></pre>"},{"location":"getting-started/#webappjob","title":"WebappJob","text":"<p><code>WebappJob</code>  is a job type for launching a web application. It can accept a function with <code>ip</code> and <code>port</code> as arguments:</p> <pre><code>from executor.engine import Engine\nfrom executor.engine.job.extend import WebappJob\nfrom http.server import HTTPServer, SimpleHTTPRequestHandler\n\ndef run_simple_httpd(ip: str, port: int):\n    server_addr = (ip, port)\n    httpd = HTTPServer(server_addr, SimpleHTTPRequestHandler)\n    httpd.serve_forever()\n\nwith Engine() as engine:\n    job = WebappJob(run_simple_httpd, ip=\"127.0.0.1\", port=8000)\n    engine.submit(job)\n    print(\"Open your browser and visit http://127.0.0.1:8000\")\n    engine.wait()\n</code></pre> <p><code>WebappJob</code> can also accept a command template as its argument:</p> <pre><code>from executor.engine import Engine\nfrom executor.engine.job.extend import WebappJob\n\nwith Engine() as engine:\n    job = WebappJob(\n        \"python -m http.server -b {ip} {port}\",\n        ip=\"127.0.0.1\", port=8000)\n    engine.submit(job)\n    print(\"Open your browser and visit http://127.0.0.1:8000\")\n    engine.wait()\n</code></pre>"},{"location":"getting-started/#cronjob","title":"CronJob","text":"<p><code>CronJob</code> is a job type for scheduling jobs periodically. It should be used with different <code>TimeCondition</code> for different scheduling strategies. For example:</p> <pre><code>from executor.engine import Engine\nfrom executor.engine.job.extend.cron import (\n    CronJob, every,\n    hourly, daily, weekly,\n    after_clock, between_clock,\n    after_weekday,\n)\n\n\ndef do_something():\n    print(\"hello\")\n\n\nwith Engine() as engine:\n    # will run the function every 10 seconds\n    job1 = CronJob(do_something, every(\"10s\"))\n    # will run the function every minute\n    job2 = CronJob(do_something, every(\"1m\"))\n    # will run the function every hour\n    job3 = CronJob(do_something, hourly)\n    # will run the function every day at 12:00\n    job4 = CronJob(do_something, daily &amp; after_clock(\"12:00\"))\n    # will run the function every week on Monday at 12:00\n    job5 = CronJob(\n        do_something,\n        weekly &amp; after_weekday(\"Monday\") &amp; after_clock(\"12:00\"))\n    # will run the function every 5min at the night\n    job6 = CronJob(do_something, every(\"5m\") &amp; between_clock(\"18:00\", \"24:00\"))\n    engine.submit(job1, job2, job3, job4, job5, job6)\n    engine.wait()\n</code></pre> <p>See CronJob for more details.</p> <p>Info</p> <p><code>CronJob</code> is a special kind of <code>SentinelJob</code>, <code>SentinelJob</code> is a more general kind of job, it will be submit other jobs when the condition is satisfied.</p>"},{"location":"getting-started/#generator-support","title":"Generator support","text":"<p><code>executor.engine</code> supports generator job, which is a special job that returns a generator.</p> <pre><code>import asyncio\nfrom executor.engine import Engine, ProcessJob\n\nengine = Engine()\n\ndef gen():\n    for i in range(10):\n        yield i\n\nasync def async_gen():\n    for i in range(10):\n        await asyncio.sleep(0.5)\n        yield i\n\nasync def main():\n    job = ProcessJob(gen)\n    await engine.submit_async(job)\n    await job.wait_until_status(\"running\")\n    for i in job.result():\n        print(i)\n\n    job = ProcessJob(async_gen)\n    await engine.submit_async(job)\n    await job.wait_until_status(\"running\")\n    async for i in job.result():\n        print(i)\n\nasyncio.run(main())\n</code></pre> <p>Info</p> <p><code>LocalJob</code>, <code>ThreadJob</code>, <code>ProcessJob</code>, <code>DaskJob</code> support generator job.</p> <p>Warning</p> <p>Do not use <code>engine.wait()</code> to wait the generator job done, because the generator job's future is done only when the generator is exhausted.</p> <p>Generator support the <code>send</code> method, you can use this feature to pass data to the generator, it allow you communicate with another thread/process:</p> <pre><code>import asyncio\nfrom executor.engine import Engine, ProcessJob\n\ndef calculator():\n    res = None\n    while True:\n        expr = yield res\n        res = eval(expr)\n\n\nasync def main():\n    with Engine() as engine:\n        job = ProcessJob(calculator)\n        await engine.submit_async(job)\n        await job.wait_until_status(\"running\")\n        g = job.result()\n        g.send(None)  # initialize the generator\n        print(g.send(\"1 + 2\"))  # 3\n        print(g.send(\"3 * 4\"))  # 12\n        print(g.send(\"(1 + 2) * 4\"))  # 12\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/#engine","title":"Engine","text":"<p><code>executor.engine</code> provides a <code>Engine</code> class for managing jobs.</p> <p>In non-async mode, engine will launch a thread to run a asyncio event loop, for scheduling jobs. Before submitting jobs, you should start this event loop by calling <code>engine.start()</code>. And you should stop the event loop by calling <code>engine.stop()</code> after all jobs are finished.</p> <pre><code>from executor.engine import Engine, ProcessJob\n\ndef add(a, b):\n    return a + b\n\nengine = Engine()\nengine.start()\njob1 = ProcessJob(add, args=(1, 2))\nengine.submit(job1)\nengine.wait_job(job1)\nprint(job1.result())  # 3\nengine.stop()\n</code></pre> <p>The <code>with statement</code> is for convenience, it will automatically start and stop the event loop:</p> <pre><code>from executor.engine import Engine, ProcessJob\n\ndef add(a, b):\n    return a + b\n\nwith Engine() as engine:\n    job1 = ProcessJob(add, args=(1, 2))\n    engine.submit(job1)\n    engine.wait_job(job1)\n    print(job1.result())  # 3\n</code></pre> <p>See the API reference for more details.</p>"},{"location":"getting-started/#engine-setting","title":"Engine setting","text":"<p>You can set some engine settings by passing a <code>EngineSetting</code> instance to the <code>Engine</code> constructor. For example, you can set the jobs number limit, turn off print traceback, etc.</p> <pre><code>from executor.engine import Engine, EngineSetting, ProcessJob\n\ndef add(a, b):\n    return a + b\n\ndef raise_exception():\n    raise Exception(\"error\")\n\nwith Engine(setting=EngineSetting(\n    max_jobs=1,  # only one job can be executed at the same time\n    print_traceback=False,\n)) as engine:\n    job1 = ProcessJob(add, args=(1, 2))\n    job2 = ProcessJob(raise_exception)\n    engine.submit(job1, job2)\n    engine.wait()\n    # job2 will not print traceback\n    print(job1.result())  # 3\n    print(job2.exception())  # Exception: error\n</code></pre> <p>More settings are available, see the API reference for more details.</p>"},{"location":"getting-started/#jobs-manager","title":"Jobs manager","text":"<p>All jobs of an engine are managed by a <code>Jobs</code> instance. It caches all jobs on disk, and provides some methods to select jobs by id, status, etc.</p> <pre><code>from executor.engine import Engine, ProcessJob\n\ndef add(a, b):\n    return a + b\n\nwith Engine() as engine:\n    job1 = ProcessJob(add, args=(1, 2))\n    engine.submit(job1)\n    print(engine.jobs.get_job_by_id(job1.id))  # will print job1\n    print(len(engine.jobs.running))  # will print 1\n    job2 = ProcessJob(add, args=(3, 4))\n    engine.submit(job2)\n    print(len(engine.jobs.running))  # will print 2\n    engine.wait()\n    print(len(engine.jobs.done))  # will print 2\n    for job in engine.jobs.done.values():  # iterate all done jobs\n        print(job.result())  # will print 3 and 7\n</code></pre> <p>See the API reference for more details.</p>"},{"location":"getting-started/#launcher-api","title":"Launcher API","text":"<p><code>executor.engine</code> provides a launcher API for launching jobs in more efficient way.</p> <pre><code>from executor.engine.launcher import launcher\nfrom executor.engine import Engine\n\n@launcher(job_type='process')\ndef add(a, b):\n    time.sleep(1)\n    return a + b\n\nwith Engine() as engine:\n    job = add.submit(1, 2)\n    engine.wait_job(job)\n    print(job.result()) # 3\n</code></pre> <p>By passing <code>async_mode=True</code> to <code>launcher</code>, you can use <code>await</code> to launch jobs:</p> <pre><code>@launcher(async_mode=True)\ndef add(a, b):\n    time.sleep(0.5)\n    return a + b\n\nasync def main():\n    job = await add.submit(1, 2)\n    await job.join()\n    print(job.result()) # 3\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/#command-line-launcher","title":"Command line launcher","text":"<p>The <code>launcher</code> can accept a <code>cmd2func</code>  instance(see cmd2func documentation for more details). In this way, the launcher will launch the <code>SubprocessJob</code> when submitting the job.</p> <pre><code>from cmd2func import cmd2func\nfrom executor.engine.launcher import launcher\nfrom executor.engine import Engine\n\n@launcher\n@cmd2func\ndef cmd_add(a, b):\n    return f\"python -c 'print({a} + {b})'\"\n\nwith Engine() as engine:\n    job = cmd_add.submit(1, 2)\n    engine.wait_job(job)\n    # will print 3 in the console\n    print(job.result()) # 0: the return code of the command\n</code></pre>"},{"location":"getting-started/#logging-settings","title":"Logging settings","text":"<p>Executor engine use <code>loguru</code> as the default logger. You can configure the logger by importing <code>executor.engine.log.logger</code>:</p> <pre><code>from executor.engine.log import logger\n\n# add file handler\nlogger.add(sys.stderr, format=\"{time} {level} {message}\", filter=\"my_module\", level=\"INFO\")\n\n# change log-string format\nlogger.add(sys.stdout, colorize=True, format=\"&lt;green&gt;{time}&lt;/green&gt; &lt;level&gt;{message}&lt;/level&gt;\")\n</code></pre> <p>See <code>loguru</code> documentation for more details.</p>"},{"location":"api-reference/condition/","title":"Condition","text":""},{"location":"api-reference/condition/#executor.engine.job.condition.Condition","title":"<code>executor.engine.job.condition.Condition</code>  <code>dataclass</code>","text":"<p>Base class for condition</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass Condition():\n    \"\"\"Base class for condition\"\"\"\n\n    def satisfy(self, engine: \"Engine\") -&gt; bool:  # pragma: no cover\n        \"\"\"Check if the condition is satisfied.\"\"\"\n        return True\n\n    def __or__(self, other: \"Condition\") -&gt; \"AnySatisfied\":\n        return AnySatisfied(conditions=[self, other])\n\n    def __and__(self, other: \"Condition\") -&gt; \"AllSatisfied\":\n        return AllSatisfied(conditions=[self, other])\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.Condition.satisfy","title":"<code>satisfy(engine)</code>","text":"<p>Check if the condition is satisfied.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>def satisfy(self, engine: \"Engine\") -&gt; bool:  # pragma: no cover\n    \"\"\"Check if the condition is satisfied.\"\"\"\n    return True\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AfterAnother","title":"<code>executor.engine.job.condition.AfterAnother</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Condition</code></p> <p>Condition that the job is executed after another job is done/failed/cancelled.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>str</code> <p>The id of the job.</p> <code>statuses</code> <code>Iterable[JobStatusType]</code> <p>The statuses of the job that satisfy the condition.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AfterAnother(Condition):\n    \"\"\"Condition that the job is executed after\n    another job is done/failed/cancelled.\n\n    Attributes:\n        job_id: The id of the job.\n        statuses: The statuses of the job that satisfy the condition.\n    \"\"\"\n\n    job_id: str\n    statuses: T.Iterable[JobStatusType] = (\"done\", \"failed\", \"cancelled\")\n\n    def satisfy(self, engine) -&gt; bool:\n        try:\n            another = engine.jobs.get_job_by_id(self.job_id)\n        except Exception:\n            return False\n        if another.status in self.statuses:\n            return True\n        else:\n            return False\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AfterOthers","title":"<code>executor.engine.job.condition.AfterOthers</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Condition</code></p> <p>Condition that the job is executed after other jobs are done/failed/cancelled.</p> <p>Attributes:</p> Name Type Description <code>job_ids</code> <code>List[str]</code> <p>The ids of the jobs.</p> <code>statuses</code> <code>Iterable[JobStatusType]</code> <p>The statuses of the jobs that satisfy the condition.</p> <code>mode</code> <code>Literal['all', 'any']</code> <p>The mode of the condition. If it is 'all', the job is executed after all other jobs are done/failed/cancelled. If it is 'any', the job is executed after any other job is done/failed/cancelled.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AfterOthers(Condition):\n    \"\"\"Condition that the job is executed after\n    other jobs are done/failed/cancelled.\n\n    Attributes:\n        job_ids: The ids of the jobs.\n        statuses: The statuses of the jobs that satisfy the condition.\n        mode: The mode of the condition. If it is 'all', the job is executed\n            after all other jobs are done/failed/cancelled. If it is 'any',\n            the job is executed after any other job is done/failed/cancelled.\n    \"\"\"\n\n    job_ids: T.List[str]\n    statuses: T.Iterable[JobStatusType] = (\"done\", \"failed\", \"cancelled\")\n    mode: T.Literal['all', 'any'] = \"all\"\n\n    def satisfy(self, engine) -&gt; bool:\n        other_job_satisfy = []\n        for id_ in self.job_ids:\n            try:\n                job = engine.jobs.get_job_by_id(id_)\n            except Exception:\n                other_job_satisfy.append(False)\n                continue\n            s_ = job.status in self.statuses\n            other_job_satisfy.append(s_)\n        if self.mode == 'all':\n            return all(other_job_satisfy)\n        else:\n            return any(other_job_satisfy)\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.Combination","title":"<code>executor.engine.job.condition.Combination</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Condition</code></p> <p>Base class for combination of conditions.</p> <p>Attributes:</p> Name Type Description <code>conditions</code> <code>List[Condition]</code> <p>The sub-conditions.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass Combination(Condition):\n    \"\"\"Base class for combination of conditions.\n\n    Attributes:\n        conditions: The sub-conditions.\n    \"\"\"\n    conditions: T.List[Condition]\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AllSatisfied","title":"<code>executor.engine.job.condition.AllSatisfied</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Combination</code></p> <p>Condition that the job is executed after all sub-conditions are satisfied.</p> <p>Attributes:</p> Name Type Description <code>conditions</code> <code>List[Condition]</code> <p>The sub-conditions.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AllSatisfied(Combination):\n    \"\"\"Condition that the job is executed after all\n    sub-conditions are satisfied.\n\n    Attributes:\n        conditions: The sub-conditions.\n    \"\"\"\n\n    conditions: T.List[Condition]\n\n    def satisfy(self, engine):\n        \"\"\"Check if the condition is satisfied.\"\"\"\n        return all([c.satisfy(engine) for c in self.conditions])\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AllSatisfied.satisfy","title":"<code>satisfy(engine)</code>","text":"<p>Check if the condition is satisfied.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>def satisfy(self, engine):\n    \"\"\"Check if the condition is satisfied.\"\"\"\n    return all([c.satisfy(engine) for c in self.conditions])\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AnySatisfied","title":"<code>executor.engine.job.condition.AnySatisfied</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Combination</code></p> <p>Condition that the job is executed after any sub-condition is satisfied.</p> <p>Attributes:</p> Name Type Description <code>conditions</code> <code>List[Condition]</code> <p>The sub-conditions.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AnySatisfied(Combination):\n    \"\"\"Condition that the job is executed after any\n    sub-condition is satisfied.\n\n    Attributes:\n        conditions: The sub-conditions.\n    \"\"\"\n\n    conditions: T.List[Condition]\n\n    def satisfy(self, engine):\n        \"\"\"Check if the condition is satisfied.\"\"\"\n        return any([c.satisfy(engine) for c in self.conditions])\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AnySatisfied.satisfy","title":"<code>satisfy(engine)</code>","text":"<p>Check if the condition is satisfied.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>def satisfy(self, engine):\n    \"\"\"Check if the condition is satisfied.\"\"\"\n    return any([c.satisfy(engine) for c in self.conditions])\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.TimeCondition","title":"<code>executor.engine.job.condition.TimeCondition</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Condition</code></p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass TimeCondition(Condition):\n    pass\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.EveryPeriod","title":"<code>executor.engine.job.condition.EveryPeriod</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>Every period.</p> <p>Attributes:</p> Name Type Description <code>period_str</code> <code>str</code> <p>The period string. format: \"1d\", \"1h\", \"1m\", \"1s\"</p> <code>last_submitted_at</code> <code>Optional[datetime]</code> <p>The last submitted time.</p> <code>immediate</code> <code>bool</code> <p>Whether to submit the job immediately.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass EveryPeriod(TimeCondition):\n    \"\"\"Every period.\n\n    Attributes:\n        period_str: The period string.\n            format: \"1d\", \"1h\", \"1m\", \"1s\"\n        last_submitted_at: The last submitted time.\n        immediate: Whether to submit the job immediately.\n    \"\"\"\n    period_str: str\n    last_submitted_at: T.Optional[datetime] = None\n    immediate: bool = False\n\n    def satisfy(self, _) -&gt; bool:\n        period = _parse_period_str(self.period_str)\n        res: bool\n        if self.last_submitted_at is None:\n            self.last_submitted_at = datetime.now()\n            res = self.immediate\n        else:\n            res = (datetime.now() - self.last_submitted_at &gt;= period)\n        if res:\n            self.last_submitted_at = datetime.now()\n        return res\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AfterClock","title":"<code>executor.engine.job.condition.AfterClock</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>After a specific clock.</p> <p>Attributes:</p> Name Type Description <code>time_str</code> <code>str</code> <p>The time string. format: \"12:00\", \"12:00:00\"</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AfterClock(TimeCondition):\n    \"\"\"After a specific clock.\n\n    Attributes:\n        time_str: The time string.\n            format: \"12:00\", \"12:00:00\"\n    \"\"\"\n    time_str: str\n\n    def satisfy(self, _) -&gt; bool:\n        hour, minute, second = _parse_clock_str(self.time_str)\n        now = datetime.now()\n        res = (\n            (now.hour &gt;= hour) &amp;\n            (now.minute &gt;= minute) &amp;\n            (now.second &gt;= second)\n        )\n        return res\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.BeforeClock","title":"<code>executor.engine.job.condition.BeforeClock</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>Before a specific clock.</p> <p>Attributes:</p> Name Type Description <code>time_str</code> <code>str</code> <p>The time string. format: \"12:00\", \"12:00:00\"</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass BeforeClock(TimeCondition):\n    \"\"\"Before a specific clock.\n\n    Attributes:\n        time_str: The time string.\n            format: \"12:00\", \"12:00:00\"\n    \"\"\"\n    time_str: str\n\n    def satisfy(self, _) -&gt; bool:\n        hour, minute, second = _parse_clock_str(self.time_str)\n        now = datetime.now()\n        res = (\n            (now.hour &lt;= hour) &amp;\n            (now.minute &lt;= minute) &amp;\n            (now.second &lt;= second)\n        )\n        return res\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AfterWeekday","title":"<code>executor.engine.job.condition.AfterWeekday</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>After a specific weekday.</p> <p>Attributes:</p> Name Type Description <code>weekday_str</code> <code>str</code> <p>The weekday string. format: \"monday\", \"mon\", \"tuesday\", \"tue\", \"wednesday\", \"wed\",     \"thursday\", \"thu\", \"friday\", \"fri\", \"saturday\", \"sat\",     \"sunday\", \"sun\"</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AfterWeekday(TimeCondition):\n    \"\"\"After a specific weekday.\n\n    Attributes:\n        weekday_str: The weekday string.\n            format: \"monday\", \"mon\", \"tuesday\", \"tue\", \"wednesday\", \"wed\",\n                \"thursday\", \"thu\", \"friday\", \"fri\", \"saturday\", \"sat\",\n                \"sunday\", \"sun\"\n    \"\"\"\n    weekday_str: str\n\n    def satisfy(self, _) -&gt; bool:\n        weekday = _parse_weekday_str(self.weekday_str)\n        now = datetime.now()\n        res = (now.weekday() &gt;= weekday)\n        return res\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.BeforeWeekday","title":"<code>executor.engine.job.condition.BeforeWeekday</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>Before a specific weekday.</p> <p>Attributes:</p> Name Type Description <code>weekday_str</code> <code>str</code> <p>The weekday string. format: \"monday\", \"mon\", \"tuesday\", \"tue\", \"wednesday\", \"wed\",     \"thursday\", \"thu\", \"friday\", \"fri\", \"saturday\", \"sat\",     \"sunday\", \"sun\"</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass BeforeWeekday(TimeCondition):\n    \"\"\"Before a specific weekday.\n\n    Attributes:\n        weekday_str: The weekday string.\n            format: \"monday\", \"mon\", \"tuesday\", \"tue\", \"wednesday\", \"wed\",\n                \"thursday\", \"thu\", \"friday\", \"fri\", \"saturday\", \"sat\",\n                \"sunday\", \"sun\"\n    \"\"\"\n    weekday_str: str\n\n    def satisfy(self, _) -&gt; bool:\n        weekday = _parse_weekday_str(self.weekday_str)\n        now = datetime.now()\n        res = (now.weekday() &lt;= weekday)\n        return res\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.AfterTimepoint","title":"<code>executor.engine.job.condition.AfterTimepoint</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>After a timepoint.</p> <p>Attributes:</p> Name Type Description <code>timepoint</code> <code>datetime</code> <p>The timepoint.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass AfterTimepoint(TimeCondition):\n    \"\"\"After a timepoint.\n\n    Attributes:\n        timepoint: The timepoint.\n    \"\"\"\n\n    timepoint: datetime\n\n    def satisfy(self, _) -&gt; bool:\n        return datetime.now() &gt; self.timepoint\n</code></pre>"},{"location":"api-reference/condition/#executor.engine.job.condition.BeforeTimepoint","title":"<code>executor.engine.job.condition.BeforeTimepoint</code>  <code>dataclass</code>","text":"<p>               Bases: <code>TimeCondition</code></p> <p>Before a timepoint.</p> <p>Attributes:</p> Name Type Description <code>timepoint</code> <code>datetime</code> <p>The timepoint.</p> Source code in <code>executor/engine/job/condition.py</code> <pre><code>@dataclass\nclass BeforeTimepoint(TimeCondition):\n    \"\"\"Before a timepoint.\n\n    Attributes:\n        timepoint: The timepoint.\n    \"\"\"\n    timepoint: datetime\n\n    def satisfy(self, _) -&gt; bool:\n        return datetime.now() &lt; self.timepoint\n</code></pre>"},{"location":"api-reference/engine/","title":"Engine","text":""},{"location":"api-reference/engine/#executor.engine.core.EngineSetting","title":"<code>executor.engine.core.EngineSetting</code>  <code>dataclass</code>","text":"<p>Engine setting.</p> <p>Parameters:</p> Name Type Description Default <code>max_thread_jobs</code> <code>Optional[int]</code> <p>Maximum number of thread jobs, if not set, no limit.</p> <code>None</code> <code>max_process_jobs</code> <code>Optional[int]</code> <p>Maximum number of process jobs, if not set, no limit.</p> <code>None</code> <code>max_dask_jobs</code> <code>Optional[int]</code> <p>Maximum number of dask jobs, if not set, no limit.</p> <code>None</code> <code>max_jobs</code> <code>Optional[int]</code> <p>Maximum number of jobs, if not set, no limit.</p> <code>20</code> <code>cache_type</code> <code>Literal['diskcache', 'none']</code> <p>Cache type, \"diskcache\" or \"none\". If set to \"diskcache\", will use diskcache package to cache job status and result. If set to \"none\", the status and result of job will only be stored in memory.</p> <code>'none'</code> <code>cache_path</code> <code>Optional[str]</code> <p>Cache path, if not set, will create a cache directory in .executor/{engine.id}.</p> <code>None</code> <code>print_traceback</code> <code>bool</code> <p>Whether to print traceback when job failed.</p> <code>True</code> <code>kwargs_inject_key</code> <code>str</code> <p>Key to inject engine to job kwargs. If set, the engine will be injected to job kwargs with the key. default is \"engine\".</p> <code>'__engine__'</code> Source code in <code>executor/engine/core.py</code> <pre><code>@dataclass\nclass EngineSetting:\n    \"\"\"Engine setting.\n\n    Args:\n        max_thread_jobs: Maximum number of thread jobs,\n            if not set, no limit.\n        max_process_jobs: Maximum number of process jobs,\n            if not set, no limit.\n        max_dask_jobs: Maximum number of dask jobs,\n            if not set, no limit.\n        max_jobs: Maximum number of jobs,\n            if not set, no limit.\n        cache_type: Cache type, \"diskcache\" or \"none\".\n            If set to \"diskcache\", will use diskcache package\n            to cache job status and result.\n            If set to \"none\", the status and result of job\n            will only be stored in memory.\n        cache_path: Cache path,\n            if not set, will create a cache directory in\n            .executor/{engine.id}.\n        print_traceback: Whether to print traceback when job failed.\n        kwargs_inject_key: Key to inject engine to job kwargs.\n            If set, the engine will be injected to job kwargs\n            with the key.\n            default is \"__engine__\".\n    \"\"\"\n    max_thread_jobs: T.Optional[int] = None\n    max_process_jobs: T.Optional[int] = None\n    max_dask_jobs: T.Optional[int] = None\n    max_jobs: T.Optional[int] = 20\n    cache_type: T.Literal[\"diskcache\", \"none\"] = \"none\"\n    cache_path: T.Optional[str] = None\n    print_traceback: bool = True\n    kwargs_inject_key: str = \"__engine__\"\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine","title":"<code>executor.engine.core.Engine</code>","text":"<p>               Bases: <code>ExecutorObj</code></p> Source code in <code>executor/engine/core.py</code> <pre><code>class Engine(ExecutorObj):\n    def __init__(\n            self,\n            setting: T.Optional[EngineSetting] = None,\n            jobs: T.Optional[Jobs] = None,\n            loop: T.Optional[asyncio.AbstractEventLoop] = None,\n            ) -&gt; None:\n        \"\"\"\n        Args:\n            setting: Engine setting. Defaults to None.\n            jobs: Jobs manager. Defaults to None.\n            loop: Event loop. Defaults to None.\n\n        Attributes:\n            setting: Engine setting.\n            resource: Resource of engine.\n            jobs: Jobs manager.\n        \"\"\"\n        super().__init__()\n        if setting is None:\n            setting = EngineSetting()\n        self.setting = setting\n        self.print_traceback = False\n        self.setup_by_setting()\n        if jobs is None:\n            if self.setting.cache_type == \"diskcache\":\n                jobs = Jobs(self.cache_dir / \"jobs\")\n            else:\n                jobs = Jobs()\n        self.jobs: Jobs = jobs\n        self._dask_client: T.Optional[\"Client\"] = None\n        self._loop = loop\n        self._loop_thread: T.Optional[Thread] = None\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Engine id={self.id}&gt;\"\n\n    def __str__(self) -&gt; str:\n        return repr(self)\n\n    @property\n    def loop(self):\n        \"\"\"Event loop of engine.\"\"\"\n        if self._loop is None:\n            loop = asyncio.new_event_loop()\n            logger.info(f\"{self} created new event loop.\")\n            self._loop = loop\n        return self._loop\n\n    @loop.setter\n    def loop(self, loop: asyncio.AbstractEventLoop):\n        self._loop = loop\n\n    def start(self):\n        \"\"\"Start event loop thread.\"\"\"\n        def run_in_thread(loop: asyncio.AbstractEventLoop):\n            logger.info(f\"{self} start event loop.\")\n            asyncio.set_event_loop(loop)\n            loop.run_forever()\n\n        if self._loop_thread is None:\n            self._loop_thread = Thread(\n                target=run_in_thread,\n                args=(self.loop,), daemon=True\n            )\n\n        if not self._loop_thread.is_alive():\n            logger.info(f\"{self} start event loop thread.\")\n            self._loop_thread.start()\n        else:\n            logger.warning(f\"Event loop thread of {self} is already running.\")\n\n    def stop(self):\n        \"\"\"Stop event loop thread.\"\"\"\n        loop = self._loop\n        if (loop is None) or (self._loop_thread is None):\n            logger.warning(f\"Event loop thread of {self} is not running.\")\n            return\n\n        if not self._loop_thread.is_alive():\n            logger.warning(f\"Event loop thread of {self} is already closed.\")\n        else:\n            logger.info(f\"{self} stop event loop.\")\n            loop.call_soon_threadsafe(loop.stop)\n            self._loop_thread.join()\n            if self._dask_client is not None:\n                asyncio.run_coroutine_threadsafe(\n                    self._dask_client.close(), loop)\n\n    def __enter__(self):\n        self.start()\n        from . launcher.core import set_default_engine\n        set_default_engine(self)\n        return self\n\n    def __exit__(self, *args):\n        self.stop()\n        from . launcher.core import set_default_engine\n        set_default_engine(None)\n\n    def setup_by_setting(self):\n        setting = self.setting\n        logger.info(f\"Load setting: {setting}\")\n        self.resource = Resource(\n            n_thread=setting.max_thread_jobs or float('inf'),\n            n_process=setting.max_process_jobs or float('inf'),\n            n_dask=setting.max_dask_jobs or float('inf'),\n            n_job=setting.max_jobs or float('inf'),\n        )\n        self.cache_dir = self.get_cache_dir()\n        self.print_traceback = setting.print_traceback\n\n    def submit(self, *jobs: Job):\n        \"\"\"Submit job to engine\"\"\"\n        if (self._loop_thread is None) or\\\n           (not self._loop_thread.is_alive()):\n            raise RuntimeError(\n                f\"Event loop thread of {self} is not running.\"\n                \" Please use engine as context manager or call engine.start().\"\n            )\n        fut = asyncio.run_coroutine_threadsafe(\n            self.submit_async(*jobs), self.loop)\n        fut.result()\n\n    async def submit_async(self, *jobs: Job):\n        \"\"\"Asynchronous interface for submit jobs to engine.\"\"\"\n        for job in jobs:\n            if job.status == \"created\":\n                job.engine = self\n                job._status = \"pending\"\n                func_var_names = job.func.__code__.co_varnames\n                if self.setting.kwargs_inject_key in func_var_names:\n                    job.kwargs[self.setting.kwargs_inject_key] = self\n                self.jobs.add(job)\n            else:\n                job.status = \"pending\"\n            assert job.engine is self, \"Job engine is not this engine.\"\n            await job.emit()\n\n    def remove(self, job: Job):\n        \"\"\"Remove job from engine.\"\"\"\n        if job.status in ('running', 'pending'):\n            fut = asyncio.run_coroutine_threadsafe(\n                job.cancel(), self.loop)\n            fut.result()\n        logger.info(f\"Remove job from engine: {job}\")\n        self.jobs.remove(job)\n\n    def cancel(self, *jobs: Job):\n        \"\"\"Cancel a job.\"\"\"\n        futures = []\n        for job in jobs:\n            fut = asyncio.run_coroutine_threadsafe(\n                job.cancel(), self.loop)\n            futures.append(fut)\n        concurrent.futures.wait(futures)\n\n    async def cancel_all_async(self):\n        \"\"\"Cancel all pending and running jobs.\"\"\"\n        running = self.jobs.running.values()\n        pending = self.jobs.pending.values()\n        tasks = []\n        for job in (pending + running):\n            tasks.append(job.cancel())\n        await asyncio.gather(*tasks)\n\n    def cancel_all(self):\n        \"\"\"Cancel all pending and running jobs.\"\"\"\n        fut = asyncio.run_coroutine_threadsafe(\n            self.cancel_all_async(), self.loop)\n        fut.result()\n\n    def wait_job(\n            self, job: Job,\n            timeout: T.Optional[float] = None,\n            ) -&gt; T.Optional[T.Any]:\n        \"\"\"Block until job is finished or timeout.\n        Return job result if job is done.\n\n        Args:\n            job: Job to wait.\n            timeout: Timeout in seconds.\n        \"\"\"\n        fut = asyncio.run_coroutine_threadsafe(\n            job.join(timeout=timeout), self.loop)\n        fut.result()\n        if job.status == \"done\":\n            return job.result()\n        else:\n            return None\n\n    def wait(\n            self,\n            timeout: T.Optional[float] = None,\n            time_delta: float = 0.2,\n            select_jobs: T.Optional[T.Callable[[Jobs], T.List[Job]]] = None,\n            ):\n        \"\"\"Block until all jobs are finished or timeout.\n\n        Args:\n            timeout: Timeout in seconds.\n            time_delta: Time interval to check job status.\n            select_jobs: Function to select jobs to wait.\n        \"\"\"\n        if select_jobs is None:\n            select_jobs = (\n                lambda jobs: jobs.running.values() + jobs.pending.values()\n            )\n        total_time = timeout if timeout is not None else float('inf')\n        while True:\n            n_wait_jobs = len(select_jobs(self.jobs))\n            if n_wait_jobs == 0:\n                break\n            if total_time &lt;= 0:\n                break\n            time.sleep(time_delta)\n            total_time -= time_delta\n\n    async def wait_async(\n            self,\n            timeout: T.Optional[float] = None,\n            time_delta: float = 0.2,\n            select_jobs: T.Optional[T.Callable[[Jobs], T.List[Job]]] = None,\n            ):\n        \"\"\"Asynchronous interface for wait.\n        Block until all jobs are finished or timeout.\n\n        Args:\n            timeout: Timeout in seconds.\n            time_delta: Time interval to check job status.\n            select_jobs: Function to select jobs to wait.\n        \"\"\"\n        if select_jobs is None:\n            select_jobs = (\n                lambda jobs: jobs.running.values() + jobs.pending.values()\n            )\n        total_time = timeout if timeout is not None else float('inf')\n        while True:\n            n_wait_jobs = len(select_jobs(self.jobs))\n            if n_wait_jobs == 0:\n                break\n            if total_time &lt;= 0:\n                break\n            await asyncio.sleep(time_delta)\n            total_time -= time_delta\n\n    async def join(\n            self,\n            jobs: T.Optional[T.List[Job]] = None,\n            timeout: T.Optional[float] = None):\n        \"\"\"Join all running and pending jobs.\"\"\"\n        if jobs is None:\n            jobs_for_join = (\n                self.jobs.running.values() +\n                self.jobs.pending.values()\n            )\n        else:\n            jobs_for_join = jobs\n        tasks = [\n            asyncio.create_task(job.join())\n            for job in jobs_for_join\n        ]\n        if len(tasks) &gt; 0:\n            await asyncio.wait(tasks, timeout=timeout)\n\n    def get_cache_dir(self) -&gt; Path:\n        \"\"\"Get cache directory for engine.\"\"\"\n        cache_path = self.setting.cache_path\n        if cache_path is not None:\n            path = cache_path\n        else:\n            path = f\".executor/{self.id}\"\n        path_obj = Path(path)\n        path_obj.mkdir(parents=True, exist_ok=True)\n        return path_obj\n\n    @property\n    def dask_client(self):\n        from .job.dask import get_default_client\n        if self._dask_client is None:\n            self._dask_client = get_default_client()\n        return self._dask_client\n\n    @dask_client.setter\n    def dask_client(self, client: \"Client\"):\n        if not client.asynchronous:\n            raise ValueError(\"Dask client must be asynchronous.\")\n        self._dask_client = client\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.loop","title":"<code>loop</code>  <code>property</code> <code>writable</code>","text":"<p>Event loop of engine.</p>"},{"location":"api-reference/engine/#executor.engine.core.Engine.__init__","title":"<code>__init__(setting=None, jobs=None, loop=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>setting</code> <code>Optional[EngineSetting]</code> <p>Engine setting. Defaults to None.</p> <code>None</code> <code>jobs</code> <code>Optional[Jobs]</code> <p>Jobs manager. Defaults to None.</p> <code>None</code> <code>loop</code> <code>Optional[AbstractEventLoop]</code> <p>Event loop. Defaults to None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>setting</code> <p>Engine setting.</p> <code>resource</code> <p>Resource of engine.</p> <code>jobs</code> <p>Jobs manager.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def __init__(\n        self,\n        setting: T.Optional[EngineSetting] = None,\n        jobs: T.Optional[Jobs] = None,\n        loop: T.Optional[asyncio.AbstractEventLoop] = None,\n        ) -&gt; None:\n    \"\"\"\n    Args:\n        setting: Engine setting. Defaults to None.\n        jobs: Jobs manager. Defaults to None.\n        loop: Event loop. Defaults to None.\n\n    Attributes:\n        setting: Engine setting.\n        resource: Resource of engine.\n        jobs: Jobs manager.\n    \"\"\"\n    super().__init__()\n    if setting is None:\n        setting = EngineSetting()\n    self.setting = setting\n    self.print_traceback = False\n    self.setup_by_setting()\n    if jobs is None:\n        if self.setting.cache_type == \"diskcache\":\n            jobs = Jobs(self.cache_dir / \"jobs\")\n        else:\n            jobs = Jobs()\n    self.jobs: Jobs = jobs\n    self._dask_client: T.Optional[\"Client\"] = None\n    self._loop = loop\n    self._loop_thread: T.Optional[Thread] = None\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.cancel","title":"<code>cancel(*jobs)</code>","text":"<p>Cancel a job.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def cancel(self, *jobs: Job):\n    \"\"\"Cancel a job.\"\"\"\n    futures = []\n    for job in jobs:\n        fut = asyncio.run_coroutine_threadsafe(\n            job.cancel(), self.loop)\n        futures.append(fut)\n    concurrent.futures.wait(futures)\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.cancel_all","title":"<code>cancel_all()</code>","text":"<p>Cancel all pending and running jobs.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def cancel_all(self):\n    \"\"\"Cancel all pending and running jobs.\"\"\"\n    fut = asyncio.run_coroutine_threadsafe(\n        self.cancel_all_async(), self.loop)\n    fut.result()\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.cancel_all_async","title":"<code>cancel_all_async()</code>  <code>async</code>","text":"<p>Cancel all pending and running jobs.</p> Source code in <code>executor/engine/core.py</code> <pre><code>async def cancel_all_async(self):\n    \"\"\"Cancel all pending and running jobs.\"\"\"\n    running = self.jobs.running.values()\n    pending = self.jobs.pending.values()\n    tasks = []\n    for job in (pending + running):\n        tasks.append(job.cancel())\n    await asyncio.gather(*tasks)\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.get_cache_dir","title":"<code>get_cache_dir()</code>","text":"<p>Get cache directory for engine.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def get_cache_dir(self) -&gt; Path:\n    \"\"\"Get cache directory for engine.\"\"\"\n    cache_path = self.setting.cache_path\n    if cache_path is not None:\n        path = cache_path\n    else:\n        path = f\".executor/{self.id}\"\n    path_obj = Path(path)\n    path_obj.mkdir(parents=True, exist_ok=True)\n    return path_obj\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.join","title":"<code>join(jobs=None, timeout=None)</code>  <code>async</code>","text":"<p>Join all running and pending jobs.</p> Source code in <code>executor/engine/core.py</code> <pre><code>async def join(\n        self,\n        jobs: T.Optional[T.List[Job]] = None,\n        timeout: T.Optional[float] = None):\n    \"\"\"Join all running and pending jobs.\"\"\"\n    if jobs is None:\n        jobs_for_join = (\n            self.jobs.running.values() +\n            self.jobs.pending.values()\n        )\n    else:\n        jobs_for_join = jobs\n    tasks = [\n        asyncio.create_task(job.join())\n        for job in jobs_for_join\n    ]\n    if len(tasks) &gt; 0:\n        await asyncio.wait(tasks, timeout=timeout)\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.remove","title":"<code>remove(job)</code>","text":"<p>Remove job from engine.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def remove(self, job: Job):\n    \"\"\"Remove job from engine.\"\"\"\n    if job.status in ('running', 'pending'):\n        fut = asyncio.run_coroutine_threadsafe(\n            job.cancel(), self.loop)\n        fut.result()\n    logger.info(f\"Remove job from engine: {job}\")\n    self.jobs.remove(job)\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.start","title":"<code>start()</code>","text":"<p>Start event loop thread.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def start(self):\n    \"\"\"Start event loop thread.\"\"\"\n    def run_in_thread(loop: asyncio.AbstractEventLoop):\n        logger.info(f\"{self} start event loop.\")\n        asyncio.set_event_loop(loop)\n        loop.run_forever()\n\n    if self._loop_thread is None:\n        self._loop_thread = Thread(\n            target=run_in_thread,\n            args=(self.loop,), daemon=True\n        )\n\n    if not self._loop_thread.is_alive():\n        logger.info(f\"{self} start event loop thread.\")\n        self._loop_thread.start()\n    else:\n        logger.warning(f\"Event loop thread of {self} is already running.\")\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.stop","title":"<code>stop()</code>","text":"<p>Stop event loop thread.</p> Source code in <code>executor/engine/core.py</code> <pre><code>def stop(self):\n    \"\"\"Stop event loop thread.\"\"\"\n    loop = self._loop\n    if (loop is None) or (self._loop_thread is None):\n        logger.warning(f\"Event loop thread of {self} is not running.\")\n        return\n\n    if not self._loop_thread.is_alive():\n        logger.warning(f\"Event loop thread of {self} is already closed.\")\n    else:\n        logger.info(f\"{self} stop event loop.\")\n        loop.call_soon_threadsafe(loop.stop)\n        self._loop_thread.join()\n        if self._dask_client is not None:\n            asyncio.run_coroutine_threadsafe(\n                self._dask_client.close(), loop)\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.submit","title":"<code>submit(*jobs)</code>","text":"<p>Submit job to engine</p> Source code in <code>executor/engine/core.py</code> <pre><code>def submit(self, *jobs: Job):\n    \"\"\"Submit job to engine\"\"\"\n    if (self._loop_thread is None) or\\\n       (not self._loop_thread.is_alive()):\n        raise RuntimeError(\n            f\"Event loop thread of {self} is not running.\"\n            \" Please use engine as context manager or call engine.start().\"\n        )\n    fut = asyncio.run_coroutine_threadsafe(\n        self.submit_async(*jobs), self.loop)\n    fut.result()\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.submit_async","title":"<code>submit_async(*jobs)</code>  <code>async</code>","text":"<p>Asynchronous interface for submit jobs to engine.</p> Source code in <code>executor/engine/core.py</code> <pre><code>async def submit_async(self, *jobs: Job):\n    \"\"\"Asynchronous interface for submit jobs to engine.\"\"\"\n    for job in jobs:\n        if job.status == \"created\":\n            job.engine = self\n            job._status = \"pending\"\n            func_var_names = job.func.__code__.co_varnames\n            if self.setting.kwargs_inject_key in func_var_names:\n                job.kwargs[self.setting.kwargs_inject_key] = self\n            self.jobs.add(job)\n        else:\n            job.status = \"pending\"\n        assert job.engine is self, \"Job engine is not this engine.\"\n        await job.emit()\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.wait","title":"<code>wait(timeout=None, time_delta=0.2, select_jobs=None)</code>","text":"<p>Block until all jobs are finished or timeout.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>Optional[float]</code> <p>Timeout in seconds.</p> <code>None</code> <code>time_delta</code> <code>float</code> <p>Time interval to check job status.</p> <code>0.2</code> <code>select_jobs</code> <code>Optional[Callable[[Jobs], List[Job]]]</code> <p>Function to select jobs to wait.</p> <code>None</code> Source code in <code>executor/engine/core.py</code> <pre><code>def wait(\n        self,\n        timeout: T.Optional[float] = None,\n        time_delta: float = 0.2,\n        select_jobs: T.Optional[T.Callable[[Jobs], T.List[Job]]] = None,\n        ):\n    \"\"\"Block until all jobs are finished or timeout.\n\n    Args:\n        timeout: Timeout in seconds.\n        time_delta: Time interval to check job status.\n        select_jobs: Function to select jobs to wait.\n    \"\"\"\n    if select_jobs is None:\n        select_jobs = (\n            lambda jobs: jobs.running.values() + jobs.pending.values()\n        )\n    total_time = timeout if timeout is not None else float('inf')\n    while True:\n        n_wait_jobs = len(select_jobs(self.jobs))\n        if n_wait_jobs == 0:\n            break\n        if total_time &lt;= 0:\n            break\n        time.sleep(time_delta)\n        total_time -= time_delta\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.wait_async","title":"<code>wait_async(timeout=None, time_delta=0.2, select_jobs=None)</code>  <code>async</code>","text":"<p>Asynchronous interface for wait. Block until all jobs are finished or timeout.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>Optional[float]</code> <p>Timeout in seconds.</p> <code>None</code> <code>time_delta</code> <code>float</code> <p>Time interval to check job status.</p> <code>0.2</code> <code>select_jobs</code> <code>Optional[Callable[[Jobs], List[Job]]]</code> <p>Function to select jobs to wait.</p> <code>None</code> Source code in <code>executor/engine/core.py</code> <pre><code>async def wait_async(\n        self,\n        timeout: T.Optional[float] = None,\n        time_delta: float = 0.2,\n        select_jobs: T.Optional[T.Callable[[Jobs], T.List[Job]]] = None,\n        ):\n    \"\"\"Asynchronous interface for wait.\n    Block until all jobs are finished or timeout.\n\n    Args:\n        timeout: Timeout in seconds.\n        time_delta: Time interval to check job status.\n        select_jobs: Function to select jobs to wait.\n    \"\"\"\n    if select_jobs is None:\n        select_jobs = (\n            lambda jobs: jobs.running.values() + jobs.pending.values()\n        )\n    total_time = timeout if timeout is not None else float('inf')\n    while True:\n        n_wait_jobs = len(select_jobs(self.jobs))\n        if n_wait_jobs == 0:\n            break\n        if total_time &lt;= 0:\n            break\n        await asyncio.sleep(time_delta)\n        total_time -= time_delta\n</code></pre>"},{"location":"api-reference/engine/#executor.engine.core.Engine.wait_job","title":"<code>wait_job(job, timeout=None)</code>","text":"<p>Block until job is finished or timeout. Return job result if job is done.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>Job to wait.</p> required <code>timeout</code> <code>Optional[float]</code> <p>Timeout in seconds.</p> <code>None</code> Source code in <code>executor/engine/core.py</code> <pre><code>def wait_job(\n        self, job: Job,\n        timeout: T.Optional[float] = None,\n        ) -&gt; T.Optional[T.Any]:\n    \"\"\"Block until job is finished or timeout.\n    Return job result if job is done.\n\n    Args:\n        job: Job to wait.\n        timeout: Timeout in seconds.\n    \"\"\"\n    fut = asyncio.run_coroutine_threadsafe(\n        job.join(timeout=timeout), self.loop)\n    fut.result()\n    if job.status == \"done\":\n        return job.result()\n    else:\n        return None\n</code></pre>"},{"location":"api-reference/extend_job/","title":"Extend job types","text":""},{"location":"api-reference/extend_job/#executor.engine.job.extend.SubprocessJob","title":"<code>executor.engine.job.extend.SubprocessJob(cmd, record_cmd=True, base_class=ThreadJob, callback=None, error_callback=None, retries=0, retry_time_delta=0.0, name=None, condition=None, wait_time_delta=0.01, redirect_out_err=False, target_dir='$current_dir', popen_kwargs=None, **attrs)</code>","text":"<p>Create a job that runs a subprocess.</p> <p>Parameters:</p> Name Type Description Default <code>cmd</code> <code>str</code> <p>The command to run.</p> required <code>record_cmd</code> <code>bool</code> <p>Whether to record the command to a file.</p> <code>True</code> <code>base_class</code> <code>Type[Job]</code> <p>The base class of the job.</p> <code>ThreadJob</code> <code>callback</code> <code>Optional[Callable[[Any], None]]</code> <p>The callback function.</p> <code>None</code> <code>error_callback</code> <code>Optional[Callable[[Exception], None]]</code> <p>The error callback function.</p> <code>None</code> <code>retries</code> <code>int</code> <p>The number of retries.</p> <code>0</code> <code>retry_time_delta</code> <code>float</code> <p>The time delta between retries.</p> <code>0.0</code> <code>name</code> <code>Optional[str]</code> <p>The name of the job.</p> <code>None</code> <code>condition</code> <code>Optional[Condition]</code> <p>The condition of the job.</p> <code>None</code> <code>wait_time_delta</code> <code>float</code> <p>The time delta between each check.</p> <code>0.01</code> <code>redirect_out_err</code> <code>bool</code> <p>Whether to redirect stdout and stderr to files.</p> <code>False</code> <code>target_dir</code> <code>str</code> <p>The target directory path for run the command. Use '$cache_dir' to represent the cache directory of the job. Use '$current_dir' to represent the current directory of the job. Default is '$current_dir'.</p> <code>'$current_dir'</code> <code>popen_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>The keyword arguments for subprocess.Popen.</p> <code>None</code> <code>**attrs</code> <p>Other attributes of the job.</p> <code>{}</code> Source code in <code>executor/engine/job/extend/subprocess.py</code> <pre><code>def SubprocessJob(\n    cmd: str, record_cmd: bool = True,\n    base_class: T.Type[Job] = ThreadJob,\n    callback: T.Optional[T.Callable[[T.Any], None]] = None,\n    error_callback: T.Optional[T.Callable[[Exception], None]] = None,\n    retries: int = 0,\n    retry_time_delta: float = 0.0,\n    name: T.Optional[str] = None,\n    condition: T.Optional[Condition] = None,\n    wait_time_delta: float = 0.01,\n    redirect_out_err: bool = False,\n    target_dir: str = \"$current_dir\",\n    popen_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n    **attrs\n):\n    \"\"\"Create a job that runs a subprocess.\n\n    Args:\n        cmd: The command to run.\n        record_cmd: Whether to record the command to a file.\n        base_class: The base class of the job.\n        callback: The callback function.\n        error_callback: The error callback function.\n        retries: The number of retries.\n        retry_time_delta: The time delta between retries.\n        name: The name of the job.\n        condition: The condition of the job.\n        wait_time_delta: The time delta between each check.\n        redirect_out_err: Whether to redirect stdout and stderr to files.\n        target_dir: The target directory path for run the command.\n            Use '$cache_dir' to represent the cache directory of the job.\n            Use '$current_dir' to represent the current directory of the job.\n            Default is '$current_dir'.\n        popen_kwargs: The keyword arguments for subprocess.Popen.\n        **attrs: Other attributes of the job.\n    \"\"\"\n    class _SubprocessJob(base_class):  # type: ignore\n        cmd: str\n        target_dir: str\n\n        repr_attrs = [\n            ('status', lambda self: self.status),\n            ('id', lambda self: self.id),\n            ('cmd', lambda self: self.cmd),\n            ('target_dir', lambda self: self.target_dir),\n            ('base_class', lambda _: base_class.__name__),\n            (\"condition\", lambda self: self.condition),\n            (\"retry_remain\", lambda self: self.retry_remain),\n        ]\n\n        def __init__(self) -&gt; None:\n            self.cmd = cmd\n            self.record_cmd = record_cmd\n            nonlocal name\n            if name is None:\n                name = cmd.split()[0]\n            self.target_dir = target_dir\n            attrs.update({\n                'cmd': cmd,\n                'target_dir': target_dir,\n            })\n            super().__init__(\n                lambda x: x,\n                callback=callback,\n                error_callback=error_callback,\n                retries=retries,\n                retry_time_delta=retry_time_delta,\n                name=name,\n                condition=condition,\n                wait_time_delta=wait_time_delta,\n                redirect_out_err=redirect_out_err,\n                **attrs\n            )\n            self.runner: T.Optional[ProcessRunner] = None\n\n        def resolve_target_dir(self, target_dir: str) -&gt; str:\n            if target_dir == \"$cache_dir\":\n                return self.cache_dir.resolve().as_posix()\n            elif target_dir == \"$current_dir\":\n                return Path.cwd().resolve().as_posix()\n            else:\n                return Path(target_dir).resolve().as_posix()\n\n        def process_func(self):\n            cmd = copy.copy(self.cmd)\n            record_cmd = copy.copy(self.record_cmd)\n            target_dir = self.resolve_target_dir(self.target_dir)\n            self.attrs.update({\n                'target_dir': target_dir,\n            })\n            self.target_dir = target_dir\n\n            cache_dir = self.cache_dir.resolve()\n            path_sh = cache_dir / 'command.sh'\n\n            def record_command():\n                with open(path_sh, 'w') as f:\n                    f.write(cmd + \"\\n\")\n\n            pkwargs = popen_kwargs or {}\n            pkwargs['cwd'] = target_dir\n\n            if self.redirect_out_err is not False:\n                if isinstance(self.redirect_out_err, str):\n                    path_stdout = Path(self.redirect_out_err)\n                    if not path_stdout.parent.exists():\n                        path_stdout.parent.mkdir(parents=True, exist_ok=True)\n                    path_stdout = self.redirect_out_err\n                    path_stderr = self.redirect_out_err\n                else:\n                    path_stdout = cache_dir / 'stdout.txt'\n                    path_stderr = cache_dir / 'stderr.txt'\n\n                def _run_cmd(runner: ProcessRunner):  # pragma: no cover\n                    runner.run(**pkwargs)\n                    if path_stdout == path_stderr:\n                        fo = open(path_stdout, 'a')\n                        fe = fo\n                    else:\n                        fo = open(path_stdout, 'a')\n                        fe = open(path_stderr, 'a')\n                    retcode = runner.write_stream_until_stop(\n                        fo, fe, flush_streams_each_time=True)\n                    fo.close()\n                    if path_stdout != path_stderr:\n                        fe.close()\n                    return retcode\n            else:\n                def _run_cmd(runner: ProcessRunner):\n                    runner.run(\n                        capture_stdout=False,\n                        capture_stderr=False,\n                        **pkwargs\n                    )\n                    retcode = runner.proc.wait()\n                    return retcode\n\n            if base_class is ThreadJob:\n                runner = ProcessRunner(cmd)\n                self.runner = runner\n\n                def run_cmd():\n                    return _run_cmd(runner)\n            else:\n                def run_cmd():\n                    runner = ProcessRunner(cmd)\n                    return _run_cmd(runner)\n\n            def func():\n                if record_cmd:\n                    record_command()\n                retcode = run_cmd()\n                if retcode &gt; 0:\n                    raise subp.SubprocessError(\n                        f\"Command '{cmd}' run failed, return code: {retcode}\")\n                return retcode\n            self.func = func\n\n        async def cancel(self):\n            if self.runner is not None:\n                self.runner.proc.terminate()\n            await super().cancel()\n\n    return _SubprocessJob()\n</code></pre>"},{"location":"api-reference/extend_job/#executor.engine.job.extend.WebappJob","title":"<code>executor.engine.job.extend.WebappJob(web_launcher, ip='127.0.0.1', port=None, base_class=ProcessJob, check_times=6, check_delta=1.0, callback=None, error_callback=None, retries=0, retry_time_delta=0.0, name=None, condition=None, wait_time_delta=0.01, redirect_out_err=False, **attrs)</code>","text":"<p>Create a job that runs a web app.</p> <p>Parameters:</p> Name Type Description Default <code>web_launcher</code> <code>Union[LauncherFunc, str]</code> <p>The function to launch the web app. The function should accept two arguments: ip and port.</p> required <code>ip</code> <code>str</code> <p>The ip address of the web app.</p> <code>'127.0.0.1'</code> <code>port</code> <code>Optional[int]</code> <p>The port of the web app. If None, will find a free port.</p> <code>None</code> <code>base_class</code> <code>Type[Job]</code> <p>The base class of the job.</p> <code>ProcessJob</code> <code>check_times</code> <code>int</code> <p>The number of times to check the web app.</p> <code>6</code> <code>check_delta</code> <code>float</code> <p>The time delta between each check.</p> <code>1.0</code> <code>callback</code> <code>Optional[Callable[[Any], None]]</code> <p>The callback function.</p> <code>None</code> <code>error_callback</code> <code>Optional[Callable[[Exception], None]]</code> <p>The error callback function.</p> <code>None</code> <code>retries</code> <code>int</code> <p>The number of retries.</p> <code>0</code> <code>retry_time_delta</code> <code>float</code> <p>The time delta between retries.</p> <code>0.0</code> <code>name</code> <code>Optional[str]</code> <p>The name of the job.</p> <code>None</code> <code>condition</code> <code>Optional[Condition]</code> <p>The condition of the job.</p> <code>None</code> <code>wait_time_delta</code> <code>float</code> <p>The time delta between each check.</p> <code>0.01</code> <code>redirect_out_err</code> <code>bool</code> <p>Whether to redirect stdout and stderr to files.</p> <code>False</code> <code>**attrs</code> <p>Other attributes of the job.</p> <code>{}</code> Source code in <code>executor/engine/job/extend/webapp.py</code> <pre><code>def WebappJob(\n    web_launcher: T.Union[LauncherFunc, str],\n    ip: str = \"127.0.0.1\", port: T.Optional[int] = None,\n    base_class: T.Type[Job] = ProcessJob,\n    check_times: int = 6,\n    check_delta: float = 1.0,\n    callback: T.Optional[T.Callable[[T.Any], None]] = None,\n    error_callback: T.Optional[T.Callable[[Exception], None]] = None,\n    retries: int = 0,\n    retry_time_delta: float = 0.0,\n    name: T.Optional[str] = None,\n    condition: T.Optional[Condition] = None,\n    wait_time_delta: float = 0.01,\n    redirect_out_err: bool = False,\n    **attrs\n):\n    \"\"\"Create a job that runs a web app.\n\n    Args:\n        web_launcher: The function to launch the web app.\n            The function should accept two arguments: ip and port.\n        ip: The ip address of the web app.\n        port: The port of the web app. If None, will find a free port.\n        base_class: The base class of the job.\n        check_times: The number of times to check the web app.\n        check_delta: The time delta between each check.\n        callback: The callback function.\n        error_callback: The error callback function.\n        retries: The number of retries.\n        retry_time_delta: The time delta between retries.\n        name: The name of the job.\n        condition: The condition of the job.\n        wait_time_delta: The time delta between each check.\n        redirect_out_err: Whether to redirect stdout and stderr to files.\n        **attrs: Other attributes of the job.\n    \"\"\"\n    class _WebappJob(base_class):  # type: ignore\n        ip: str\n        port: T.Optional[int]\n\n        repr_attrs = [\n            ('status', lambda self: self.status),\n            ('id', lambda self: self.id),\n            ('addr', lambda self: f'{self.ip}:{self.port}'),\n            ('base_class', lambda _: base_class.__name__),\n            (\"condition\", lambda self: self.condition),\n            (\"retry_remain\", lambda self: self.retry_remain),\n        ]\n\n        def __init__(self) -&gt; None:\n            self.ip = ip\n            if ip not in (\"127.0.0.1\", \"localhost\", \"0.0.0.0\"):\n                raise NotImplementedError(\n                    \"WebappJob now only support launch in local mechine.\")\n            self.port = port\n            self.check_web_launcher(web_launcher)\n            self.web_launcher = web_launcher\n            self.check_times = check_times\n            self.check_delta = check_delta\n            if isinstance(web_launcher, str):\n                attrs.update({\"cmd\": web_launcher})\n            super().__init__(\n                lambda x: x, callback=callback,\n                error_callback=error_callback,\n                retries=retries,\n                retry_time_delta=retry_time_delta,\n                name=name,\n                condition=condition,\n                wait_time_delta=wait_time_delta,\n                redirect_out_err=redirect_out_err,\n                **attrs\n            )\n\n        @staticmethod\n        def check_web_launcher(web_launcher: T.Union[LauncherFunc, str]):\n            if isinstance(web_launcher, str):\n                cmd_temp = web_launcher\n                if ('{ip}' not in cmd_temp) or ('{port}' not in cmd_temp):\n                    raise ValueError(\n                        \"web_launcher should has ip and port placeholder.\")\n            else:\n                if not callable(web_launcher):\n                    raise TypeError(\n                        \"web_launcher should be a callable object or str.\")\n\n        def consume_resource(self) -&gt; bool:\n            if super().consume_resource():\n                if self.port is None:\n                    self.port = PortManager.get_port()\n                else:\n                    PortManager.consume_port(self.port)\n                self.attrs.update({\"address\": f\"{self.ip}:{self.port}\"})\n                return True\n            else:  # pragma: no cover\n                return False\n\n        def release_resource(self) -&gt; bool:\n            if self.port is None:  # pragma: no cover\n                return False\n            if super().release_resource():\n                PortManager.release_port(self.port)\n                return True\n            else:  # pragma: no cover\n                return False\n\n        def process_func(self):\n            web_launcher = copy.copy(self.web_launcher)\n            if self.port is None:  # pragma: no cover\n                raise ExecutorError(\"Unreachable code.\")\n            ip, port = copy.copy(self.ip), copy.copy(self.port)\n            check_times = copy.copy(self.check_times)\n            check_delta = copy.copy(self.check_delta)\n\n            def check_port(pid: int) -&gt; bool:  # pragma: no cover\n                for _ in range(check_times):\n                    time.sleep(check_delta)\n                    if PortManager.process_has_port(pid, ip, port):\n                        return True\n                    print(f\"Process is not listen on {ip}:{port}. Try again.\")\n                return False\n\n            if isinstance(web_launcher, str):\n                cmd = web_launcher.format(ip=ip, port=port)\n\n                def func():  # pragma: no cover\n                    runner = ProcessRunner(cmd)\n                    runner.run()\n                    if check_port(runner.proc.pid):\n                        retcode = runner.write_stream_until_stop(\n                            sys.stdout, sys.stderr)\n                        sys.exit(retcode)\n                    else:\n                        runner.proc.terminate()\n                        raise IOError(f\"Process is not listen on {ip}:{port}.\")\n            else:\n                def func():  # pragma: no cover\n                    proc = LokyProcess(target=web_launcher, args=(ip, port))\n                    proc.start()\n                    pid = proc.pid\n                    if check_port(pid):\n                        proc.join()\n                    else:\n                        proc.terminate()\n                        raise IOError(f\"Process is not listen on {ip}:{port}.\")\n\n            self.func = func\n            super().process_func()\n    return _WebappJob()\n</code></pre>"},{"location":"api-reference/extend_job/#executor.engine.job.extend.SentinelJob","title":"<code>executor.engine.job.extend.SentinelJob(func, sentinel_condition, job_type='process', time_delta=0.01, sentinel_attrs=None, **attrs)</code>","text":"<p>Submit a job when the sentinel condition is met.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The function to be executed.</p> required <code>sentinel_condition</code> <code>Condition</code> <p>The sentinel condition.</p> required <code>job_type</code> <code>Union[str, Type[Job]]</code> <p>The type of the job.</p> <code>'process'</code> <code>time_delta</code> <code>float</code> <p>The time delta between each check of the sentinel condition.</p> <code>0.01</code> <code>sentinel_attrs</code> <code>Optional[dict]</code> <p>The attributes of the sentinel job.</p> <code>None</code> <code>**attrs</code> <p>The attributes of the job.</p> <code>{}</code> Source code in <code>executor/engine/job/extend/sentinel.py</code> <pre><code>def SentinelJob(\n        func: T.Callable,\n        sentinel_condition: Condition,\n        job_type: T.Union[str, T.Type[Job]] = \"process\",\n        time_delta: float = 0.01,\n        sentinel_attrs: T.Optional[dict] = None,\n        **attrs\n        ):\n    \"\"\"Submit a job when the sentinel condition is met.\n\n    Args:\n        func: The function to be executed.\n        sentinel_condition: The sentinel condition.\n        job_type: The type of the job.\n        time_delta: The time delta between each check\n            of the sentinel condition.\n        sentinel_attrs: The attributes of the sentinel job.\n        **attrs: The attributes of the job.\n    \"\"\"\n    sentinel_attrs = sentinel_attrs or {}\n    if \"name\" not in sentinel_attrs:\n        sentinel_attrs[\"name\"] = f\"sentinel-{func.__name__}\"\n\n    base_class: T.Type[Job]\n    if isinstance(job_type, str):\n        if job_type == \"process\":\n            base_class = ProcessJob\n        elif job_type == \"thread\":\n            base_class = ThreadJob\n        else:\n            base_class = LocalJob\n    else:\n        base_class = job_type\n\n    async def sentinel(__engine__: \"Engine\"):\n        while True:\n            if sentinel_condition.satisfy(__engine__):\n                job = base_class(func, **attrs)\n                await __engine__.submit_async(job)\n            await asyncio.sleep(time_delta)\n\n    sentinel_job = LocalJob(\n        sentinel,\n        **sentinel_attrs\n    )\n    return sentinel_job\n</code></pre>"},{"location":"api-reference/extend_job/#executor.engine.job.extend.CronJob","title":"<code>executor.engine.job.extend.CronJob(func, time_condition, job_type='process', time_delta=0.01, sentinel_attrs=None, **attrs)</code>","text":"<p>Submit a job periodically.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The function to be executed.</p> required <code>time_period</code> <p>The time period.</p> required <code>job_type</code> <code>Union[str, Type[Job]]</code> <p>The type of the job.</p> <code>'process'</code> <code>time_delta</code> <code>float</code> <p>The time delta between each check of the sentinel condition.</p> <code>0.01</code> <code>sentinel_attrs</code> <code>Optional[dict]</code> <p>The attributes of the sentinel job.</p> <code>None</code> <code>**attrs</code> <p>The attributes of the job.</p> <code>{}</code> Source code in <code>executor/engine/job/extend/cron.py</code> <pre><code>def CronJob(\n        func: T.Callable,\n        time_condition: TimeCondition,\n        job_type: T.Union[str, T.Type[Job]] = \"process\",\n        time_delta: float = 0.01,\n        sentinel_attrs: T.Optional[dict] = None,\n        **attrs\n        ):\n    \"\"\"Submit a job periodically.\n\n    Args:\n        func: The function to be executed.\n        time_period: The time period.\n        job_type: The type of the job.\n        time_delta: The time delta between each\n            check of the sentinel condition.\n        sentinel_attrs: The attributes of the sentinel job.\n        **attrs: The attributes of the job.\n    \"\"\"\n    sentinel_attrs = sentinel_attrs or {}\n    if \"name\" not in sentinel_attrs:\n        sentinel_attrs[\"name\"] = f\"cron-sentinel-{func.__name__}\"\n    sentinel_job = SentinelJob(\n        func,\n        time_condition,\n        job_type,\n        time_delta,\n        sentinel_attrs,\n        **attrs\n    )\n    return sentinel_job\n</code></pre>"},{"location":"api-reference/job/","title":"Job","text":""},{"location":"api-reference/job/#executor.engine.job.base.Job","title":"<code>executor.engine.job.base.Job</code>","text":"<p>               Bases: <code>ExecutorObj</code></p> Source code in <code>executor/engine/job/base.py</code> <pre><code>class Job(ExecutorObj):\n\n    status = JobStatusAttr()\n    repr_attrs: T.List[T.Tuple[str, T.Callable[[\"Job\"], T.Any]]] = [\n        (\"status\", lambda self: self.status),\n        (\"id\", lambda self: self.id),\n        (\"func\", lambda self: get_callable_name(self.func)),\n        (\"condition\", lambda self: self.condition),\n        (\"retry_remain\", lambda self: self.retry_remain),\n    ]\n\n    func: T.Callable\n    condition: T.Optional[Condition]\n    retry_remain: int\n\n    def __init__(\n            self,\n            func: T.Callable,\n            args: T.Optional[tuple] = None,\n            kwargs: T.Optional[dict] = None,\n            callback: T.Optional[T.Callable[[T.Any], None]] = None,\n            error_callback: T.Optional[T.Callable[[Exception], None]] = None,\n            retries: int = 0,\n            retry_time_delta: float = 0.0,\n            name: T.Optional[str] = None,\n            condition: T.Optional[Condition] = None,\n            wait_time_delta: float = 0.01,\n            redirect_out_err: T.Union[bool, str] = False,\n            change_dir: bool = False,\n            **attrs\n            ) -&gt; None:\n        \"\"\"Base class for job.\n\n        Args:\n            func: The function to be executed.\n            args: The positional arguments to be passed to the function.\n            kwargs: The keyword arguments to be passed to the function.\n            callback: The callback function to be called when the job is done.\n            error_callback: The callback function to be called\n                when the job is failed.\n            retries: The number of retries when the job is failed.\n            retry_time_delta: The time delta between retries.\n            name: The name of the job.\n            condition: The condition of the job.\n            wait_time_delta: The time delta between each\n                check of the condition.\n            redirect_out_err: Whether to redirect the stdout\n                and stderr to the log. If is a string, it will be\n                used as the path of the log file.\n            change_dir: Whether to change the working directory\n                to the log directory.\n            **attrs: The attributes of the job.\n        \"\"\"\n        super().__init__()\n        self.future = JobFuture(self.id)\n        self.func = func\n        self.args = args or tuple()\n        self.kwargs = kwargs or {}\n        if callback is not None:\n            self.future.add_done_callback(callback)\n        if error_callback is not None:\n            self.future.add_error_callback(error_callback)\n        self.retries = retries\n        self.retry_remain = retries\n        self.retry_time_delta = retry_time_delta\n        self.engine: T.Optional[\"Engine\"] = None\n        self._status: str = \"created\"\n        self.name = name or func.__name__\n        self.attrs = attrs\n        self.task: T.Optional[asyncio.Task] = None\n        self.condition = condition\n        self.wait_time_delta = wait_time_delta\n        self.redirect_out_err = redirect_out_err\n        self.change_dir = change_dir\n        self.created_time: datetime = datetime.now()\n        self.submit_time: T.Optional[datetime] = None\n        self.stoped_time: T.Optional[datetime] = None\n        self._executor: T.Any = None\n        self.dep_job_ids: T.List[str] = []\n\n    def __repr__(self) -&gt; str:\n        attrs = []\n        for attr_name, attr_func in self.repr_attrs:\n            attr_value = attr_func(self)\n            if bool(attr_value) is False:\n                continue\n            attrs.append(f\"{attr_name}={attr_value}\")\n        attr_str = \" \".join(attrs)\n        return f\"&lt;{self.__class__.__name__} {attr_str}&gt;\"\n\n    def __str__(self) -&gt; str:\n        return repr(self)\n\n    def has_resource(self) -&gt; bool:\n        \"\"\"Check if the job has resource to run.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            return self.engine.resource.n_job &gt; 0\n\n    def consume_resource(self) -&gt; bool:\n        \"\"\"Consume the resource of the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_job -= 1\n            return True\n\n    def release_resource(self) -&gt; bool:\n        \"\"\"Release the resource of the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_job += 1\n            return True\n\n    def resolve_dependencies(self) -&gt; None:\n        \"\"\"Resolve args and kwargs\n        and auto specify the condition.\"\"\"\n        dep_jobs_ids: T.List[str] = []\n        args = itertools.chain(self.args, self.kwargs.values())\n        for arg in args:\n            if isinstance(arg, JobFuture):\n                dep_jobs_ids.append(arg.job_id)\n        if len(dep_jobs_ids) &gt; 0:\n            after_others = AfterOthers(dep_jobs_ids)\n            if self.condition is None:\n                self.condition = after_others\n            else:\n                self.condition = AllSatisfied([self.condition, after_others])\n        self.dep_job_ids = dep_jobs_ids\n\n    async def _resolve_arg(self, arg: T.Union[JobFuture, T.Any]) -&gt; T.Any:\n        if isinstance(arg, JobFuture):\n            assert self.engine is not None\n            job = self.engine.jobs.get_job_by_id(arg.job_id)\n            if job.status == \"done\":\n                return job.result()\n            elif job.status == \"failed\":\n                msg = f\"Job {self} cancelled because \" \\\n                      f\"of upstream job {job} failed.\"\n                logger.warning(msg)\n                await self.cancel()\n                raise StopResolve(msg)\n            elif job.status == \"cancelled\":\n                msg = f\"Job {self} cancelled because \" \\\n                      f\"of upstream job {job} cancelled.\"\n                logger.warning(msg)\n                await self.cancel()\n                raise StopResolve(msg)\n            else:  # pragma: no cover\n                raise ExecutorError(\"Unreachable code.\")\n        else:\n            return arg\n\n    async def resolve_args(self):\n        \"\"\"Resolve args and kwargs.\"\"\"\n        if len(self.dep_job_ids) &gt; 0:\n            args = []\n            kwargs = {}\n            for arg in self.args:\n                resolved = await self._resolve_arg(arg)\n                args.append(resolved)\n            for key, value in self.kwargs.items():\n                resolved = await self._resolve_arg(value)\n                kwargs[key] = resolved\n            self.args = tuple(args)\n            self.kwargs = kwargs\n\n    def runnable(self) -&gt; bool:\n        \"\"\"Check if the job is runnable.\n        Job is runnable if:\n        1. engine is not None.\n        2. condition is None and condition is satisfied.\n        3. has resource.\"\"\"\n        if self.engine is None:\n            return False\n        if self.condition is not None:\n            return self.condition.satisfy(self.engine) and self.has_resource()\n        else:\n            return self.has_resource()\n\n    async def emit(self) -&gt; asyncio.Task:\n        \"\"\"Emit the job to the engine.\"\"\"\n        logger.info(f\"Emit job {self}, watting for run.\")\n        if self.status != 'pending':\n            raise InvalidStateError(self, ['pending'])\n        self.resolve_dependencies()\n        self.submit_time = datetime.now()\n        loop = asyncio.get_running_loop()\n        task = loop.create_task(self.wait_and_run())\n        self.task = task\n        return task\n\n    def process_func(self):\n        \"\"\"Process(decorate) the target func, before run.\n        For example, let the func\n        change the dir, redirect the stdout and stderr\n        before the actual run.\"\"\"\n        cache_dir = self.cache_dir.resolve()\n        is_redirect = (self.redirect_out_err is not False)\n        if is_redirect and (not isinstance(self.func, CaptureOut)):\n            if isinstance(self.redirect_out_err, str):\n                path_stdout = Path(self.redirect_out_err)\n                path_stderr = Path(self.redirect_out_err)\n            else:\n                path_stdout = cache_dir / 'stdout.txt'\n                path_stderr = cache_dir / 'stderr.txt'\n            self.func = CaptureOut(self.func, path_stdout, path_stderr)\n        if self.change_dir:\n            self.func = ChDir(self.func, cache_dir)\n\n    async def wait_and_run(self):\n        \"\"\"Wait for the condition satisfied and run the job.\"\"\"\n        while True:\n            if self.runnable() and self.consume_resource():\n                logger.info(f\"Start run job {self}\")\n                self.process_func()\n                try:\n                    await self.resolve_args()\n                except StopResolve:\n                    break\n                self.status = \"running\"\n                try:\n                    res = await self.run()\n                    if not isinstance(res, GeneratorWrapper):\n                        await self.on_done(res)\n                    else:\n                        self.future.set_result(res)\n                    return res\n                except Exception as e:\n                    await self.on_failed(e)\n                    break\n            else:\n                await asyncio.sleep(self.wait_time_delta)\n\n    async def run(self):\n        \"\"\"Run the job.\"\"\"\n        if inspect.isgeneratorfunction(self.func) or inspect.isasyncgenfunction(self.func):  # noqa: E501\n            return await self.run_generator()\n        else:\n            return await self.run_function()\n\n    async def run_function(self):  # pragma: no cover\n        \"\"\"Run the job as a function.\"\"\"\n        msg = f\"{type(self).__name__} does not implement \" \\\n              \"run_function method.\"\n        raise NotImplementedError(msg)\n\n    async def run_generator(self):  # pragma: no cover\n        \"\"\"Run the job as a generator.\"\"\"\n        msg = f\"{type(self).__name__} does not implement \" \\\n              \"run_generator method.\"\n        raise NotImplementedError(msg)\n\n    async def rerun(self, check_status: bool = True):\n        \"\"\"Rerun the job.\"\"\"\n        _valid_status: T.List[JobStatusType] = [\"cancelled\", \"done\", \"failed\"]\n        if check_status and (self.status not in _valid_status):\n            raise InvalidStateError(self, _valid_status)\n        logger.info(f\"Rerun job {self}\")\n        self.status = \"pending\"\n        await self.emit()\n\n    def _on_finish(self, new_status: JobStatusType = \"done\"):\n        self.status = new_status\n        self.release_resource()\n\n    async def on_done(self, res):\n        \"\"\"Callback when the job is done.\"\"\"\n        logger.info(f\"Job {self} done.\")\n        self.future.set_result(res)\n        for callback in self.future.done_callbacks:\n            if inspect.iscoroutinefunction(callback):\n                await callback(res)\n            else:\n                callback(res)\n        self._on_finish(\"done\")\n\n    async def on_failed(self, e: Exception):\n        \"\"\"Callback when the job is failed.\"\"\"\n        logger.error(f\"Job {self} failed: {repr(e)}\")\n        assert self.engine is not None\n        if self.engine.print_traceback:\n            logger.exception(e)\n        self.future.set_exception(e)\n        for err_callback in self.future.error_callbacks:\n            if inspect.iscoroutinefunction(err_callback):\n                await err_callback(e)\n            else:\n                err_callback(e)\n        if self.retry_remain &gt; 0:\n            self._on_finish(\"pending\")\n            self.retry_remain -= 1\n            await asyncio.sleep(self.retry_time_delta)\n            await self.rerun(check_status=False)\n        else:\n            self._on_finish(\"failed\")\n\n    async def cancel(self):\n        \"\"\"Cancel the job.\"\"\"\n        logger.info(f\"Cancel job {self}.\")\n        self.task.cancel()\n        if self.status == \"running\":\n            try:\n                self.clear_context()\n            except Exception as e:  # pragma: no cover\n                print(str(e))\n            finally:\n                self._on_finish(\"cancelled\")\n        elif self.status == \"pending\":\n            self.status = \"cancelled\"\n\n    def clear_context(self):\n        \"\"\"Clear the context of the job.\"\"\"\n        pass\n\n    def result(self) -&gt; T.Any:\n        \"\"\"Get the result of the job.\"\"\"\n        res = self.future.result()\n        if not isinstance(res, GeneratorWrapper):\n            if self.status != \"done\":\n                raise InvalidStateError(self, ['done'])\n        return res\n\n    def exception(self):\n        \"\"\"Get the exception of the job.\"\"\"\n        return self.future.exception()\n\n    def serialization(self) -&gt; bytes:\n        \"\"\"Serialize the job to bytes.\"\"\"\n        job = copy(self)\n        job.task = None\n        job.engine = None\n        job._executor = None\n        bytes_ = cloudpickle.dumps(job)\n        return bytes_\n\n    @staticmethod\n    def deserialization(bytes_: bytes) -&gt; \"Job\":\n        \"\"\"Deserialize the job from bytes.\"\"\"\n        job: \"Job\" = cloudpickle.loads(bytes_)\n        return job\n\n    async def join(self, timeout: T.Optional[float] = None):\n        \"\"\"Wait for the job done.\"\"\"\n        if self.task is None:\n            raise InvalidStateError(self, valid_job_statuses)\n        await asyncio.wait([self.task], timeout=timeout)\n\n    async def wait_until(\n        self, check_func: T.Callable[[\"Job\"], bool],\n        timeout: T.Optional[float] = None\n    ):\n        \"\"\"Wait until the check_func return True.\"\"\"\n        total_time = 0.0\n        while not check_func(self):\n            await asyncio.sleep(self.wait_time_delta)\n            total_time += self.wait_time_delta\n            if (timeout is not None) and total_time &gt; timeout:\n                raise asyncio.TimeoutError\n\n    async def wait_until_status(\n            self, status: JobStatusType,\n            timeout: T.Optional[float] = None):\n        \"\"\"Wait until the job is in the target status.\"\"\"\n        await self.wait_until(lambda job: job.status == status, timeout)\n\n    @property\n    def cache_dir(self) -&gt; T.Optional[Path]:\n        \"\"\"Get the cache dir of the job.\"\"\"\n        if self.engine is None:\n            return None\n        parent = self.engine.cache_dir\n        path = parent / self.id\n        path.mkdir(parents=True, exist_ok=True)\n        return path\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.cache_dir","title":"<code>cache_dir</code>  <code>property</code>","text":"<p>Get the cache dir of the job.</p>"},{"location":"api-reference/job/#executor.engine.job.base.Job.__init__","title":"<code>__init__(func, args=None, kwargs=None, callback=None, error_callback=None, retries=0, retry_time_delta=0.0, name=None, condition=None, wait_time_delta=0.01, redirect_out_err=False, change_dir=False, **attrs)</code>","text":"<p>Base class for job.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The function to be executed.</p> required <code>args</code> <code>Optional[tuple]</code> <p>The positional arguments to be passed to the function.</p> <code>None</code> <code>kwargs</code> <code>Optional[dict]</code> <p>The keyword arguments to be passed to the function.</p> <code>None</code> <code>callback</code> <code>Optional[Callable[[Any], None]]</code> <p>The callback function to be called when the job is done.</p> <code>None</code> <code>error_callback</code> <code>Optional[Callable[[Exception], None]]</code> <p>The callback function to be called when the job is failed.</p> <code>None</code> <code>retries</code> <code>int</code> <p>The number of retries when the job is failed.</p> <code>0</code> <code>retry_time_delta</code> <code>float</code> <p>The time delta between retries.</p> <code>0.0</code> <code>name</code> <code>Optional[str]</code> <p>The name of the job.</p> <code>None</code> <code>condition</code> <code>Optional[Condition]</code> <p>The condition of the job.</p> <code>None</code> <code>wait_time_delta</code> <code>float</code> <p>The time delta between each check of the condition.</p> <code>0.01</code> <code>redirect_out_err</code> <code>Union[bool, str]</code> <p>Whether to redirect the stdout and stderr to the log. If is a string, it will be used as the path of the log file.</p> <code>False</code> <code>change_dir</code> <code>bool</code> <p>Whether to change the working directory to the log directory.</p> <code>False</code> <code>**attrs</code> <p>The attributes of the job.</p> <code>{}</code> Source code in <code>executor/engine/job/base.py</code> <pre><code>def __init__(\n        self,\n        func: T.Callable,\n        args: T.Optional[tuple] = None,\n        kwargs: T.Optional[dict] = None,\n        callback: T.Optional[T.Callable[[T.Any], None]] = None,\n        error_callback: T.Optional[T.Callable[[Exception], None]] = None,\n        retries: int = 0,\n        retry_time_delta: float = 0.0,\n        name: T.Optional[str] = None,\n        condition: T.Optional[Condition] = None,\n        wait_time_delta: float = 0.01,\n        redirect_out_err: T.Union[bool, str] = False,\n        change_dir: bool = False,\n        **attrs\n        ) -&gt; None:\n    \"\"\"Base class for job.\n\n    Args:\n        func: The function to be executed.\n        args: The positional arguments to be passed to the function.\n        kwargs: The keyword arguments to be passed to the function.\n        callback: The callback function to be called when the job is done.\n        error_callback: The callback function to be called\n            when the job is failed.\n        retries: The number of retries when the job is failed.\n        retry_time_delta: The time delta between retries.\n        name: The name of the job.\n        condition: The condition of the job.\n        wait_time_delta: The time delta between each\n            check of the condition.\n        redirect_out_err: Whether to redirect the stdout\n            and stderr to the log. If is a string, it will be\n            used as the path of the log file.\n        change_dir: Whether to change the working directory\n            to the log directory.\n        **attrs: The attributes of the job.\n    \"\"\"\n    super().__init__()\n    self.future = JobFuture(self.id)\n    self.func = func\n    self.args = args or tuple()\n    self.kwargs = kwargs or {}\n    if callback is not None:\n        self.future.add_done_callback(callback)\n    if error_callback is not None:\n        self.future.add_error_callback(error_callback)\n    self.retries = retries\n    self.retry_remain = retries\n    self.retry_time_delta = retry_time_delta\n    self.engine: T.Optional[\"Engine\"] = None\n    self._status: str = \"created\"\n    self.name = name or func.__name__\n    self.attrs = attrs\n    self.task: T.Optional[asyncio.Task] = None\n    self.condition = condition\n    self.wait_time_delta = wait_time_delta\n    self.redirect_out_err = redirect_out_err\n    self.change_dir = change_dir\n    self.created_time: datetime = datetime.now()\n    self.submit_time: T.Optional[datetime] = None\n    self.stoped_time: T.Optional[datetime] = None\n    self._executor: T.Any = None\n    self.dep_job_ids: T.List[str] = []\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.cancel","title":"<code>cancel()</code>  <code>async</code>","text":"<p>Cancel the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def cancel(self):\n    \"\"\"Cancel the job.\"\"\"\n    logger.info(f\"Cancel job {self}.\")\n    self.task.cancel()\n    if self.status == \"running\":\n        try:\n            self.clear_context()\n        except Exception as e:  # pragma: no cover\n            print(str(e))\n        finally:\n            self._on_finish(\"cancelled\")\n    elif self.status == \"pending\":\n        self.status = \"cancelled\"\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.clear_context","title":"<code>clear_context()</code>","text":"<p>Clear the context of the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def clear_context(self):\n    \"\"\"Clear the context of the job.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.consume_resource","title":"<code>consume_resource()</code>","text":"<p>Consume the resource of the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def consume_resource(self) -&gt; bool:\n    \"\"\"Consume the resource of the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_job -= 1\n        return True\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.deserialization","title":"<code>deserialization(bytes_)</code>  <code>staticmethod</code>","text":"<p>Deserialize the job from bytes.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>@staticmethod\ndef deserialization(bytes_: bytes) -&gt; \"Job\":\n    \"\"\"Deserialize the job from bytes.\"\"\"\n    job: \"Job\" = cloudpickle.loads(bytes_)\n    return job\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.emit","title":"<code>emit()</code>  <code>async</code>","text":"<p>Emit the job to the engine.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def emit(self) -&gt; asyncio.Task:\n    \"\"\"Emit the job to the engine.\"\"\"\n    logger.info(f\"Emit job {self}, watting for run.\")\n    if self.status != 'pending':\n        raise InvalidStateError(self, ['pending'])\n    self.resolve_dependencies()\n    self.submit_time = datetime.now()\n    loop = asyncio.get_running_loop()\n    task = loop.create_task(self.wait_and_run())\n    self.task = task\n    return task\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.exception","title":"<code>exception()</code>","text":"<p>Get the exception of the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def exception(self):\n    \"\"\"Get the exception of the job.\"\"\"\n    return self.future.exception()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.has_resource","title":"<code>has_resource()</code>","text":"<p>Check if the job has resource to run.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def has_resource(self) -&gt; bool:\n    \"\"\"Check if the job has resource to run.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        return self.engine.resource.n_job &gt; 0\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.join","title":"<code>join(timeout=None)</code>  <code>async</code>","text":"<p>Wait for the job done.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def join(self, timeout: T.Optional[float] = None):\n    \"\"\"Wait for the job done.\"\"\"\n    if self.task is None:\n        raise InvalidStateError(self, valid_job_statuses)\n    await asyncio.wait([self.task], timeout=timeout)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.on_done","title":"<code>on_done(res)</code>  <code>async</code>","text":"<p>Callback when the job is done.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def on_done(self, res):\n    \"\"\"Callback when the job is done.\"\"\"\n    logger.info(f\"Job {self} done.\")\n    self.future.set_result(res)\n    for callback in self.future.done_callbacks:\n        if inspect.iscoroutinefunction(callback):\n            await callback(res)\n        else:\n            callback(res)\n    self._on_finish(\"done\")\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.on_failed","title":"<code>on_failed(e)</code>  <code>async</code>","text":"<p>Callback when the job is failed.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def on_failed(self, e: Exception):\n    \"\"\"Callback when the job is failed.\"\"\"\n    logger.error(f\"Job {self} failed: {repr(e)}\")\n    assert self.engine is not None\n    if self.engine.print_traceback:\n        logger.exception(e)\n    self.future.set_exception(e)\n    for err_callback in self.future.error_callbacks:\n        if inspect.iscoroutinefunction(err_callback):\n            await err_callback(e)\n        else:\n            err_callback(e)\n    if self.retry_remain &gt; 0:\n        self._on_finish(\"pending\")\n        self.retry_remain -= 1\n        await asyncio.sleep(self.retry_time_delta)\n        await self.rerun(check_status=False)\n    else:\n        self._on_finish(\"failed\")\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.process_func","title":"<code>process_func()</code>","text":"<p>Process(decorate) the target func, before run. For example, let the func change the dir, redirect the stdout and stderr before the actual run.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def process_func(self):\n    \"\"\"Process(decorate) the target func, before run.\n    For example, let the func\n    change the dir, redirect the stdout and stderr\n    before the actual run.\"\"\"\n    cache_dir = self.cache_dir.resolve()\n    is_redirect = (self.redirect_out_err is not False)\n    if is_redirect and (not isinstance(self.func, CaptureOut)):\n        if isinstance(self.redirect_out_err, str):\n            path_stdout = Path(self.redirect_out_err)\n            path_stderr = Path(self.redirect_out_err)\n        else:\n            path_stdout = cache_dir / 'stdout.txt'\n            path_stderr = cache_dir / 'stderr.txt'\n        self.func = CaptureOut(self.func, path_stdout, path_stderr)\n    if self.change_dir:\n        self.func = ChDir(self.func, cache_dir)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.release_resource","title":"<code>release_resource()</code>","text":"<p>Release the resource of the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def release_resource(self) -&gt; bool:\n    \"\"\"Release the resource of the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_job += 1\n        return True\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.rerun","title":"<code>rerun(check_status=True)</code>  <code>async</code>","text":"<p>Rerun the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def rerun(self, check_status: bool = True):\n    \"\"\"Rerun the job.\"\"\"\n    _valid_status: T.List[JobStatusType] = [\"cancelled\", \"done\", \"failed\"]\n    if check_status and (self.status not in _valid_status):\n        raise InvalidStateError(self, _valid_status)\n    logger.info(f\"Rerun job {self}\")\n    self.status = \"pending\"\n    await self.emit()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.resolve_args","title":"<code>resolve_args()</code>  <code>async</code>","text":"<p>Resolve args and kwargs.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def resolve_args(self):\n    \"\"\"Resolve args and kwargs.\"\"\"\n    if len(self.dep_job_ids) &gt; 0:\n        args = []\n        kwargs = {}\n        for arg in self.args:\n            resolved = await self._resolve_arg(arg)\n            args.append(resolved)\n        for key, value in self.kwargs.items():\n            resolved = await self._resolve_arg(value)\n            kwargs[key] = resolved\n        self.args = tuple(args)\n        self.kwargs = kwargs\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.resolve_dependencies","title":"<code>resolve_dependencies()</code>","text":"<p>Resolve args and kwargs and auto specify the condition.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def resolve_dependencies(self) -&gt; None:\n    \"\"\"Resolve args and kwargs\n    and auto specify the condition.\"\"\"\n    dep_jobs_ids: T.List[str] = []\n    args = itertools.chain(self.args, self.kwargs.values())\n    for arg in args:\n        if isinstance(arg, JobFuture):\n            dep_jobs_ids.append(arg.job_id)\n    if len(dep_jobs_ids) &gt; 0:\n        after_others = AfterOthers(dep_jobs_ids)\n        if self.condition is None:\n            self.condition = after_others\n        else:\n            self.condition = AllSatisfied([self.condition, after_others])\n    self.dep_job_ids = dep_jobs_ids\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.result","title":"<code>result()</code>","text":"<p>Get the result of the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def result(self) -&gt; T.Any:\n    \"\"\"Get the result of the job.\"\"\"\n    res = self.future.result()\n    if not isinstance(res, GeneratorWrapper):\n        if self.status != \"done\":\n            raise InvalidStateError(self, ['done'])\n    return res\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Run the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def run(self):\n    \"\"\"Run the job.\"\"\"\n    if inspect.isgeneratorfunction(self.func) or inspect.isasyncgenfunction(self.func):  # noqa: E501\n        return await self.run_generator()\n    else:\n        return await self.run_function()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.run_function","title":"<code>run_function()</code>  <code>async</code>","text":"<p>Run the job as a function.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def run_function(self):  # pragma: no cover\n    \"\"\"Run the job as a function.\"\"\"\n    msg = f\"{type(self).__name__} does not implement \" \\\n          \"run_function method.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.run_generator","title":"<code>run_generator()</code>  <code>async</code>","text":"<p>Run the job as a generator.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def run_generator(self):  # pragma: no cover\n    \"\"\"Run the job as a generator.\"\"\"\n    msg = f\"{type(self).__name__} does not implement \" \\\n          \"run_generator method.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.runnable","title":"<code>runnable()</code>","text":"<p>Check if the job is runnable. Job is runnable if: 1. engine is not None. 2. condition is None and condition is satisfied. 3. has resource.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def runnable(self) -&gt; bool:\n    \"\"\"Check if the job is runnable.\n    Job is runnable if:\n    1. engine is not None.\n    2. condition is None and condition is satisfied.\n    3. has resource.\"\"\"\n    if self.engine is None:\n        return False\n    if self.condition is not None:\n        return self.condition.satisfy(self.engine) and self.has_resource()\n    else:\n        return self.has_resource()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.serialization","title":"<code>serialization()</code>","text":"<p>Serialize the job to bytes.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>def serialization(self) -&gt; bytes:\n    \"\"\"Serialize the job to bytes.\"\"\"\n    job = copy(self)\n    job.task = None\n    job.engine = None\n    job._executor = None\n    bytes_ = cloudpickle.dumps(job)\n    return bytes_\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.wait_and_run","title":"<code>wait_and_run()</code>  <code>async</code>","text":"<p>Wait for the condition satisfied and run the job.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def wait_and_run(self):\n    \"\"\"Wait for the condition satisfied and run the job.\"\"\"\n    while True:\n        if self.runnable() and self.consume_resource():\n            logger.info(f\"Start run job {self}\")\n            self.process_func()\n            try:\n                await self.resolve_args()\n            except StopResolve:\n                break\n            self.status = \"running\"\n            try:\n                res = await self.run()\n                if not isinstance(res, GeneratorWrapper):\n                    await self.on_done(res)\n                else:\n                    self.future.set_result(res)\n                return res\n            except Exception as e:\n                await self.on_failed(e)\n                break\n        else:\n            await asyncio.sleep(self.wait_time_delta)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.wait_until","title":"<code>wait_until(check_func, timeout=None)</code>  <code>async</code>","text":"<p>Wait until the check_func return True.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def wait_until(\n    self, check_func: T.Callable[[\"Job\"], bool],\n    timeout: T.Optional[float] = None\n):\n    \"\"\"Wait until the check_func return True.\"\"\"\n    total_time = 0.0\n    while not check_func(self):\n        await asyncio.sleep(self.wait_time_delta)\n        total_time += self.wait_time_delta\n        if (timeout is not None) and total_time &gt; timeout:\n            raise asyncio.TimeoutError\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.base.Job.wait_until_status","title":"<code>wait_until_status(status, timeout=None)</code>  <code>async</code>","text":"<p>Wait until the job is in the target status.</p> Source code in <code>executor/engine/job/base.py</code> <pre><code>async def wait_until_status(\n        self, status: JobStatusType,\n        timeout: T.Optional[float] = None):\n    \"\"\"Wait until the job is in the target status.\"\"\"\n    await self.wait_until(lambda job: job.status == status, timeout)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob","title":"<code>executor.engine.job.process.ProcessJob</code>","text":"<p>               Bases: <code>Job</code></p> <p>Job that runs in a process.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>class ProcessJob(Job):\n    \"\"\"Job that runs in a process.\"\"\"\"\"\n\n    def has_resource(self) -&gt; bool:\n        \"\"\"Check if the job has enough resource to run.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            return (\n                super().has_resource() and\n                (self.engine.resource.n_process &gt; 0)\n            )\n\n    def consume_resource(self) -&gt; bool:\n        \"\"\"Consume resource for the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_process -= 1\n            return (\n                super().consume_resource() and\n                True\n            )\n\n    def release_resource(self) -&gt; bool:\n        \"\"\"Release resource for the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_process += 1\n            return (\n                super().release_resource() and\n                True\n            )\n\n    async def run_function(self):\n        \"\"\"Run job in process pool.\"\"\"\n        func = functools.partial(self.func, *self.args, **self.kwargs)\n        if iscoroutinefunction(func):\n            func = functools.partial(run_async_func, func)\n        self._executor = ProcessPoolExecutor(1)\n        loop = asyncio.get_running_loop()\n        fut = loop.run_in_executor(self._executor, func)\n        result = await fut\n        return result\n\n    async def run_generator(self):\n        \"\"\"Run job as a generator.\"\"\"\n        func = functools.partial(self.func, *self.args, **self.kwargs)\n        self._executor = ProcessPoolExecutor(\n            1, initializer=_gen_initializer, initargs=(func,))\n        result = create_generator_wrapper(self)\n        return result\n\n    async def cancel(self):\n        \"\"\"Cancel job.\"\"\"\n        if self.status == \"running\":\n            self._executor.shutdown(wait=True, kill_workers=True)\n        await super().cancel()\n\n    def clear_context(self):\n        \"\"\"Clear context.\"\"\"\n        self._executor.shutdown(wait=True, kill_workers=True)\n        self._executor = None\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.cancel","title":"<code>cancel()</code>  <code>async</code>","text":"<p>Cancel job.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>async def cancel(self):\n    \"\"\"Cancel job.\"\"\"\n    if self.status == \"running\":\n        self._executor.shutdown(wait=True, kill_workers=True)\n    await super().cancel()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.clear_context","title":"<code>clear_context()</code>","text":"<p>Clear context.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>def clear_context(self):\n    \"\"\"Clear context.\"\"\"\n    self._executor.shutdown(wait=True, kill_workers=True)\n    self._executor = None\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.consume_resource","title":"<code>consume_resource()</code>","text":"<p>Consume resource for the job.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>def consume_resource(self) -&gt; bool:\n    \"\"\"Consume resource for the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_process -= 1\n        return (\n            super().consume_resource() and\n            True\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.has_resource","title":"<code>has_resource()</code>","text":"<p>Check if the job has enough resource to run.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>def has_resource(self) -&gt; bool:\n    \"\"\"Check if the job has enough resource to run.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        return (\n            super().has_resource() and\n            (self.engine.resource.n_process &gt; 0)\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.release_resource","title":"<code>release_resource()</code>","text":"<p>Release resource for the job.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>def release_resource(self) -&gt; bool:\n    \"\"\"Release resource for the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_process += 1\n        return (\n            super().release_resource() and\n            True\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.run_function","title":"<code>run_function()</code>  <code>async</code>","text":"<p>Run job in process pool.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>async def run_function(self):\n    \"\"\"Run job in process pool.\"\"\"\n    func = functools.partial(self.func, *self.args, **self.kwargs)\n    if iscoroutinefunction(func):\n        func = functools.partial(run_async_func, func)\n    self._executor = ProcessPoolExecutor(1)\n    loop = asyncio.get_running_loop()\n    fut = loop.run_in_executor(self._executor, func)\n    result = await fut\n    return result\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.process.ProcessJob.run_generator","title":"<code>run_generator()</code>  <code>async</code>","text":"<p>Run job as a generator.</p> Source code in <code>executor/engine/job/process.py</code> <pre><code>async def run_generator(self):\n    \"\"\"Run job as a generator.\"\"\"\n    func = functools.partial(self.func, *self.args, **self.kwargs)\n    self._executor = ProcessPoolExecutor(\n        1, initializer=_gen_initializer, initargs=(func,))\n    result = create_generator_wrapper(self)\n    return result\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob","title":"<code>executor.engine.job.thread.ThreadJob</code>","text":"<p>               Bases: <code>Job</code></p> <p>Job that runs in a thread.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>class ThreadJob(Job):\n    \"\"\"Job that runs in a thread.\"\"\"\n\n    def has_resource(self) -&gt; bool:\n        \"\"\"Check if the job has enough resource to run.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            return (\n                super().has_resource() and\n                (self.engine.resource.n_thread &gt; 0)\n            )\n\n    def consume_resource(self) -&gt; bool:\n        \"\"\"Consume resource for the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_thread -= 1\n            return (\n                super().consume_resource() and\n                True\n            )\n\n    def release_resource(self) -&gt; bool:\n        \"\"\"Release resource for the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_thread += 1\n            return (\n                super().release_resource() and\n                True\n            )\n\n    async def run_function(self):\n        \"\"\"Run job in thread pool.\"\"\"\n        func = functools.partial(self.func, *self.args, **self.kwargs)\n        if iscoroutinefunction(func):\n            func = functools.partial(run_async_func, func)\n        self._executor = ThreadPoolExecutor(1)\n        loop = asyncio.get_running_loop()\n        fut = loop.run_in_executor(self._executor, func)\n        result = await fut\n        return result\n\n    async def run_generator(self):\n        \"\"\"Run job as a generator.\"\"\"\n        func = functools.partial(self.func, *self.args, **self.kwargs)\n        self._executor = ThreadPoolExecutor(\n            1, initializer=_gen_initializer, initargs=(func,))\n        result = create_generator_wrapper(self)\n        return result\n\n    async def cancel(self):\n        \"\"\"Cancel job.\"\"\"\n        if self.status == \"running\":\n            self._executor.shutdown()\n        await super().cancel()\n\n    def clear_context(self):\n        \"\"\"Clear context.\"\"\"\n        self._executor.shutdown()\n        self._executor = None\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.cancel","title":"<code>cancel()</code>  <code>async</code>","text":"<p>Cancel job.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>async def cancel(self):\n    \"\"\"Cancel job.\"\"\"\n    if self.status == \"running\":\n        self._executor.shutdown()\n    await super().cancel()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.clear_context","title":"<code>clear_context()</code>","text":"<p>Clear context.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>def clear_context(self):\n    \"\"\"Clear context.\"\"\"\n    self._executor.shutdown()\n    self._executor = None\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.consume_resource","title":"<code>consume_resource()</code>","text":"<p>Consume resource for the job.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>def consume_resource(self) -&gt; bool:\n    \"\"\"Consume resource for the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_thread -= 1\n        return (\n            super().consume_resource() and\n            True\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.has_resource","title":"<code>has_resource()</code>","text":"<p>Check if the job has enough resource to run.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>def has_resource(self) -&gt; bool:\n    \"\"\"Check if the job has enough resource to run.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        return (\n            super().has_resource() and\n            (self.engine.resource.n_thread &gt; 0)\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.release_resource","title":"<code>release_resource()</code>","text":"<p>Release resource for the job.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>def release_resource(self) -&gt; bool:\n    \"\"\"Release resource for the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_thread += 1\n        return (\n            super().release_resource() and\n            True\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.run_function","title":"<code>run_function()</code>  <code>async</code>","text":"<p>Run job in thread pool.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>async def run_function(self):\n    \"\"\"Run job in thread pool.\"\"\"\n    func = functools.partial(self.func, *self.args, **self.kwargs)\n    if iscoroutinefunction(func):\n        func = functools.partial(run_async_func, func)\n    self._executor = ThreadPoolExecutor(1)\n    loop = asyncio.get_running_loop()\n    fut = loop.run_in_executor(self._executor, func)\n    result = await fut\n    return result\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.thread.ThreadJob.run_generator","title":"<code>run_generator()</code>  <code>async</code>","text":"<p>Run job as a generator.</p> Source code in <code>executor/engine/job/thread.py</code> <pre><code>async def run_generator(self):\n    \"\"\"Run job as a generator.\"\"\"\n    func = functools.partial(self.func, *self.args, **self.kwargs)\n    self._executor = ThreadPoolExecutor(\n        1, initializer=_gen_initializer, initargs=(func,))\n    result = create_generator_wrapper(self)\n    return result\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.local.LocalJob","title":"<code>executor.engine.job.local.LocalJob</code>","text":"<p>               Bases: <code>Job</code></p> Source code in <code>executor/engine/job/local.py</code> <pre><code>class LocalJob(Job):\n    async def run_function(self):\n        \"\"\"Run job in local thread.\"\"\"\n        if iscoroutinefunction(self.func):\n            res = await self.func(*self.args, **self.kwargs)\n        else:\n            res = self.func(*self.args, **self.kwargs)\n        return res\n\n    async def run_generator(self):\n        \"\"\"Run job as a generator.\"\"\"\n        return create_generator_wrapper(self)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.local.LocalJob.run_function","title":"<code>run_function()</code>  <code>async</code>","text":"<p>Run job in local thread.</p> Source code in <code>executor/engine/job/local.py</code> <pre><code>async def run_function(self):\n    \"\"\"Run job in local thread.\"\"\"\n    if iscoroutinefunction(self.func):\n        res = await self.func(*self.args, **self.kwargs)\n    else:\n        res = self.func(*self.args, **self.kwargs)\n    return res\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.local.LocalJob.run_generator","title":"<code>run_generator()</code>  <code>async</code>","text":"<p>Run job as a generator.</p> Source code in <code>executor/engine/job/local.py</code> <pre><code>async def run_generator(self):\n    \"\"\"Run job as a generator.\"\"\"\n    return create_generator_wrapper(self)\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob","title":"<code>executor.engine.job.dask.DaskJob</code>","text":"<p>               Bases: <code>Job</code></p> <p>Job that runs with Dask.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>class DaskJob(Job):\n    \"\"\"Job that runs with Dask.\"\"\"\n\n    def has_resource(self) -&gt; bool:\n        \"\"\"Check if the job has enough resource to run.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            return (\n                super().has_resource() and\n                (self.engine.resource.n_dask &gt; 0)\n            )\n\n    def consume_resource(self) -&gt; bool:\n        \"\"\"Consume resource for the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_dask -= 1\n            return (\n                super().consume_resource() and\n                True\n            )\n\n    def release_resource(self) -&gt; bool:\n        \"\"\"Release resource for the job.\"\"\"\n        if self.engine is None:\n            return False\n        else:\n            self.engine.resource.n_dask += 1\n            return (\n                super().release_resource() and\n                True\n            )\n\n    async def run_function(self):\n        \"\"\"Run job with Dask.\"\"\"\n        client = self.engine.dask_client\n        func = functools.partial(self.func, *self.args, **self.kwargs)\n        if iscoroutinefunction(func):\n            func = functools.partial(run_async_func, func)\n        fut = client.submit(func)\n        self._executor = fut\n        result = await fut\n        return result\n\n    async def run_generator(self):\n        \"\"\"Run job as a generator.\"\"\"\n        client = self.engine.dask_client\n        func = functools.partial(self.func, *self.args, **self.kwargs)\n        fut = client.submit(func)\n        self._executor = client.get_executor(pure=False)\n        result = create_generator_wrapper(self, fut)\n        return result\n\n    async def cancel(self):\n        \"\"\"Cancel job.\"\"\"\"\"\n        if self.status == \"running\":\n            await self._executor.cancel()\n        await super().cancel()\n\n    def clear_context(self):\n        \"\"\"Clear context.\"\"\"\n        self._executor = None\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.cancel","title":"<code>cancel()</code>  <code>async</code>","text":"<p>Cancel job.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>async def cancel(self):\n    \"\"\"Cancel job.\"\"\"\"\"\n    if self.status == \"running\":\n        await self._executor.cancel()\n    await super().cancel()\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.clear_context","title":"<code>clear_context()</code>","text":"<p>Clear context.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>def clear_context(self):\n    \"\"\"Clear context.\"\"\"\n    self._executor = None\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.consume_resource","title":"<code>consume_resource()</code>","text":"<p>Consume resource for the job.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>def consume_resource(self) -&gt; bool:\n    \"\"\"Consume resource for the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_dask -= 1\n        return (\n            super().consume_resource() and\n            True\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.has_resource","title":"<code>has_resource()</code>","text":"<p>Check if the job has enough resource to run.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>def has_resource(self) -&gt; bool:\n    \"\"\"Check if the job has enough resource to run.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        return (\n            super().has_resource() and\n            (self.engine.resource.n_dask &gt; 0)\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.release_resource","title":"<code>release_resource()</code>","text":"<p>Release resource for the job.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>def release_resource(self) -&gt; bool:\n    \"\"\"Release resource for the job.\"\"\"\n    if self.engine is None:\n        return False\n    else:\n        self.engine.resource.n_dask += 1\n        return (\n            super().release_resource() and\n            True\n        )\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.run_function","title":"<code>run_function()</code>  <code>async</code>","text":"<p>Run job with Dask.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>async def run_function(self):\n    \"\"\"Run job with Dask.\"\"\"\n    client = self.engine.dask_client\n    func = functools.partial(self.func, *self.args, **self.kwargs)\n    if iscoroutinefunction(func):\n        func = functools.partial(run_async_func, func)\n    fut = client.submit(func)\n    self._executor = fut\n    result = await fut\n    return result\n</code></pre>"},{"location":"api-reference/job/#executor.engine.job.dask.DaskJob.run_generator","title":"<code>run_generator()</code>  <code>async</code>","text":"<p>Run job as a generator.</p> Source code in <code>executor/engine/job/dask.py</code> <pre><code>async def run_generator(self):\n    \"\"\"Run job as a generator.\"\"\"\n    client = self.engine.dask_client\n    func = functools.partial(self.func, *self.args, **self.kwargs)\n    fut = client.submit(func)\n    self._executor = client.get_executor(pure=False)\n    result = create_generator_wrapper(self, fut)\n    return result\n</code></pre>"},{"location":"api-reference/job_store/","title":"Job manager","text":""},{"location":"api-reference/job_store/#executor.engine.manager.Jobs","title":"<code>executor.engine.manager.Jobs</code>","text":"<p>Jobs manager.</p> <p>Attributes:</p> Name Type Description <code>pending</code> <code>JobStore</code> <p>Pending jobs.</p> <code>running</code> <code>JobStore</code> <p>Running jobs.</p> <code>done</code> <code>JobStore</code> <p>Done jobs.</p> <code>failed</code> <code>JobStore</code> <p>Failed jobs.</p> <code>cancelled</code> <code>JobStore</code> <p>Cancelled jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>class Jobs:\n    \"\"\"Jobs manager.\n\n    Attributes:\n        pending: Pending jobs.\n        running: Running jobs.\n        done: Done jobs.\n        failed: Failed jobs.\n        cancelled: Cancelled jobs.\n    \"\"\"\n    valid_statuses = valid_job_statuses\n    pending: JobStore\n    running: JobStore\n    done: JobStore\n    failed: JobStore\n    cancelled: JobStore\n\n    def __init__(self, cache_path: T.Optional[Path] = None):\n        self.cache_path = cache_path\n        self._stores: T.Dict[str, JobStore] = {}\n        s: str\n        for s in self.valid_statuses:\n            if cache_path is None:\n                store = JobStore(None)\n            else:\n                path = cache_path / s\n                if path.exists():\n                    store = JobStore.load_from_cache(path)\n                else:\n                    store = JobStore(path)\n            self._stores[s] = store\n        self.set_attrs_for_read()\n\n    def update_from_cache(self, clear_old=True):\n        \"\"\"Update jobs from cache.\"\"\"\n        for store in self._stores.values():\n            store.update_from_cache(clear_old=clear_old)\n\n    def set_attrs_for_read(self):\n        self.pending = self._stores['pending']\n        self.running = self._stores['running']\n        self.done = self._stores['done']\n        self.failed = self._stores['failed']\n        self.cancelled = self._stores['cancelled']\n\n    def set_engine(self, engine: \"Engine\"):\n        \"\"\"Set engine for all jobs.\"\"\"\n        for job in self.all_jobs():\n            job.engine = engine\n\n    def clear(self, statuses: T.List[JobStatusType]):\n        \"\"\"Clear jobs by status.\"\"\"\n        for s in statuses:\n            self._stores[s].clear()\n\n    def clear_non_active(self):\n        \"\"\"Clear non-active jobs.\"\"\"\n        self.clear([\"done\", \"failed\", \"cancelled\"])\n\n    def clear_all(self):\n        \"\"\"Clear all jobs.\"\"\"\n        self.clear(self.valid_statuses)\n\n    def add(self, job: Job):\n        \"\"\"Add job to store.\"\"\"\n        store = self._stores[job.status]\n        store[job.id] = job\n\n    def remove(self, job: Job):\n        \"\"\"Remove job from store.\"\"\"\n        for tp in self.valid_statuses:\n            store = self._stores[tp]\n            if job.id in store:\n                store.pop(job.id)\n\n    def move_job_store(\n            self, job: Job,\n            new_status: JobStatusType,\n            old_status: T.Optional[JobStatusType] = None):\n        \"\"\"Move job to another store.\"\"\"\n        if old_status is None:\n            old_status = job.status\n        if old_status == new_status:\n            return\n        old_store = self._stores[old_status]\n        new_store = self._stores[new_status]\n        new_store[job.id] = old_store.pop(job.id)\n\n    def get_job_by_id(self, job_id: str) -&gt; Job:\n        \"\"\"Get job by id.\"\"\"\n        for status in self.valid_statuses:\n            store = self._stores[status]\n            if job_id in store:\n                return store[job_id]\n        raise JobNotFoundError(job_id)\n\n    def __contains__(self, job: T.Union[str, Job]):\n        if isinstance(job, Job):\n            job_id = job.id\n        else:\n            job_id = job\n        try:\n            self.get_job_by_id(job_id)\n            return True\n        except JobNotFoundError:\n            return False\n\n    def all_jobs(self) -&gt; T.List[Job]:\n        \"\"\"Get all jobs.\"\"\"\n        return list(iter(self))\n\n    def __iter__(self):\n        \"\"\"Iterate all jobs.\"\"\"\n        for status in self.valid_statuses:\n            store = self._stores[status]\n            for job in store.values():\n                yield job\n\n    def __len__(self):\n        return sum(len(store) for store in self._stores.values())\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate all jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate all jobs.\"\"\"\n    for status in self.valid_statuses:\n        store = self._stores[status]\n        for job in store.values():\n            yield job\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.add","title":"<code>add(job)</code>","text":"<p>Add job to store.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def add(self, job: Job):\n    \"\"\"Add job to store.\"\"\"\n    store = self._stores[job.status]\n    store[job.id] = job\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.all_jobs","title":"<code>all_jobs()</code>","text":"<p>Get all jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def all_jobs(self) -&gt; T.List[Job]:\n    \"\"\"Get all jobs.\"\"\"\n    return list(iter(self))\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.clear","title":"<code>clear(statuses)</code>","text":"<p>Clear jobs by status.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def clear(self, statuses: T.List[JobStatusType]):\n    \"\"\"Clear jobs by status.\"\"\"\n    for s in statuses:\n        self._stores[s].clear()\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.clear_all","title":"<code>clear_all()</code>","text":"<p>Clear all jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def clear_all(self):\n    \"\"\"Clear all jobs.\"\"\"\n    self.clear(self.valid_statuses)\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.clear_non_active","title":"<code>clear_non_active()</code>","text":"<p>Clear non-active jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def clear_non_active(self):\n    \"\"\"Clear non-active jobs.\"\"\"\n    self.clear([\"done\", \"failed\", \"cancelled\"])\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.get_job_by_id","title":"<code>get_job_by_id(job_id)</code>","text":"<p>Get job by id.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def get_job_by_id(self, job_id: str) -&gt; Job:\n    \"\"\"Get job by id.\"\"\"\n    for status in self.valid_statuses:\n        store = self._stores[status]\n        if job_id in store:\n            return store[job_id]\n    raise JobNotFoundError(job_id)\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.move_job_store","title":"<code>move_job_store(job, new_status, old_status=None)</code>","text":"<p>Move job to another store.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def move_job_store(\n        self, job: Job,\n        new_status: JobStatusType,\n        old_status: T.Optional[JobStatusType] = None):\n    \"\"\"Move job to another store.\"\"\"\n    if old_status is None:\n        old_status = job.status\n    if old_status == new_status:\n        return\n    old_store = self._stores[old_status]\n    new_store = self._stores[new_status]\n    new_store[job.id] = old_store.pop(job.id)\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.remove","title":"<code>remove(job)</code>","text":"<p>Remove job from store.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def remove(self, job: Job):\n    \"\"\"Remove job from store.\"\"\"\n    for tp in self.valid_statuses:\n        store = self._stores[tp]\n        if job.id in store:\n            store.pop(job.id)\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.set_engine","title":"<code>set_engine(engine)</code>","text":"<p>Set engine for all jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def set_engine(self, engine: \"Engine\"):\n    \"\"\"Set engine for all jobs.\"\"\"\n    for job in self.all_jobs():\n        job.engine = engine\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.Jobs.update_from_cache","title":"<code>update_from_cache(clear_old=True)</code>","text":"<p>Update jobs from cache.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def update_from_cache(self, clear_old=True):\n    \"\"\"Update jobs from cache.\"\"\"\n    for store in self._stores.values():\n        store.update_from_cache(clear_old=clear_old)\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore","title":"<code>executor.engine.manager.JobStore</code>","text":"<p>Store jobs.</p> <p>Attributes:</p> Name Type Description <code>cache</code> <code>Optional[Cache]</code> <p>The cache on disk(Use diskcache package). See: disk-cache's doc for more details.</p> <code>mem</code> <code>Dict[str, Job]</code> <p>In memory store.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>class JobStore():\n    \"\"\"Store jobs.\n\n    Attributes:\n        cache: The cache on disk(Use diskcache package).\n            See:\n            [disk-cache's doc](https://github.com/grantjenks/python-diskcache)\n            for more details.\n        mem: In memory store.\n    \"\"\"\n\n    cache: T.Optional[Cache]\n    mem: T.Dict[str, Job]\n\n    def __init__(self, cache_path: T.Optional[Path] = None):\n        \"\"\"Init.\n\n        Args:\n            cache_path: Cache path.\n        \"\"\"\n        if cache_path is not None:\n            self.cache = Cache(str(cache_path))\n        else:\n            self.cache = None\n        self.mem: T.Dict[str, Job] = dict()\n\n    @classmethod\n    def load_from_cache(cls, path: Path):\n        \"\"\"Load from cache.\"\"\"\n        store = cls(path)\n        store.update_from_cache()\n        return store\n\n    def update_from_cache(self, clear_old=False):\n        \"\"\"Update from cache.\"\"\"\n        if clear_old:\n            self.mem.clear()\n        if self.cache is not None:\n            for key in self.cache:\n                job = self.get_from_cache(key)\n                self.mem[key] = job\n\n    def get_from_cache(self, key: str) -&gt; Job:\n        \"\"\"Get from cache.\"\"\"\n        if self.cache is None:\n            raise RuntimeError(\"No cache\")\n        bytes_ = self.cache[key]\n        job = Job.deserialization(bytes_)\n        return job\n\n    def set_to_cache(self, key: str, val: Job):\n        \"\"\"Set job to cache.\"\"\"\n        bytes_ = val.serialization()\n        if self.cache is not None:\n            self.cache[key] = bytes_\n\n    def __setitem__(self, key: str, val: Job):\n        self.mem[key] = val\n        if self.cache is not None:\n            self.set_to_cache(key, val)\n\n    def __getitem__(self, key: str) -&gt; Job:\n        return self.mem[key]\n\n    def __contains__(self, key: str) -&gt; bool:\n        return key in self.mem\n\n    def clear(self):\n        \"\"\"Clear all jobs.\"\"\"\n        self.mem.clear()\n        if self.cache is not None:\n            self.cache.clear()\n\n    def pop(self, key: str) -&gt; Job:\n        \"\"\"Pop a job from store.\"\"\"\n        job = self.mem.pop(key)\n        if self.cache is not None:\n            self.cache.pop(key)\n        return job\n\n    def values(self) -&gt; T.List[Job]:\n        \"\"\"Get all values(Job).\"\"\"\n        vals = list(self.mem.values())\n        return vals\n\n    def keys(self) -&gt; T.List[str]:\n        \"\"\"Get all keys(Job's id).\"\"\"\n        return list(self.mem.keys())\n\n    def items(self) -&gt; T.List[T.Tuple[str, Job]]:\n        \"\"\"Get all key-value pairs.\"\"\"\n        return list(self.mem.items())\n\n    def __del__(self):\n        if self.cache is not None:\n            self.cache.close()\n\n    def __len__(self):\n        return len(self.mem)\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.__init__","title":"<code>__init__(cache_path=None)</code>","text":"<p>Init.</p> <p>Parameters:</p> Name Type Description Default <code>cache_path</code> <code>Optional[Path]</code> <p>Cache path.</p> <code>None</code> Source code in <code>executor/engine/manager.py</code> <pre><code>def __init__(self, cache_path: T.Optional[Path] = None):\n    \"\"\"Init.\n\n    Args:\n        cache_path: Cache path.\n    \"\"\"\n    if cache_path is not None:\n        self.cache = Cache(str(cache_path))\n    else:\n        self.cache = None\n    self.mem: T.Dict[str, Job] = dict()\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.clear","title":"<code>clear()</code>","text":"<p>Clear all jobs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def clear(self):\n    \"\"\"Clear all jobs.\"\"\"\n    self.mem.clear()\n    if self.cache is not None:\n        self.cache.clear()\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.get_from_cache","title":"<code>get_from_cache(key)</code>","text":"<p>Get from cache.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def get_from_cache(self, key: str) -&gt; Job:\n    \"\"\"Get from cache.\"\"\"\n    if self.cache is None:\n        raise RuntimeError(\"No cache\")\n    bytes_ = self.cache[key]\n    job = Job.deserialization(bytes_)\n    return job\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.items","title":"<code>items()</code>","text":"<p>Get all key-value pairs.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def items(self) -&gt; T.List[T.Tuple[str, Job]]:\n    \"\"\"Get all key-value pairs.\"\"\"\n    return list(self.mem.items())\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.keys","title":"<code>keys()</code>","text":"<p>Get all keys(Job's id).</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def keys(self) -&gt; T.List[str]:\n    \"\"\"Get all keys(Job's id).\"\"\"\n    return list(self.mem.keys())\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.load_from_cache","title":"<code>load_from_cache(path)</code>  <code>classmethod</code>","text":"<p>Load from cache.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>@classmethod\ndef load_from_cache(cls, path: Path):\n    \"\"\"Load from cache.\"\"\"\n    store = cls(path)\n    store.update_from_cache()\n    return store\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.pop","title":"<code>pop(key)</code>","text":"<p>Pop a job from store.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def pop(self, key: str) -&gt; Job:\n    \"\"\"Pop a job from store.\"\"\"\n    job = self.mem.pop(key)\n    if self.cache is not None:\n        self.cache.pop(key)\n    return job\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.set_to_cache","title":"<code>set_to_cache(key, val)</code>","text":"<p>Set job to cache.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def set_to_cache(self, key: str, val: Job):\n    \"\"\"Set job to cache.\"\"\"\n    bytes_ = val.serialization()\n    if self.cache is not None:\n        self.cache[key] = bytes_\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.update_from_cache","title":"<code>update_from_cache(clear_old=False)</code>","text":"<p>Update from cache.</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def update_from_cache(self, clear_old=False):\n    \"\"\"Update from cache.\"\"\"\n    if clear_old:\n        self.mem.clear()\n    if self.cache is not None:\n        for key in self.cache:\n            job = self.get_from_cache(key)\n            self.mem[key] = job\n</code></pre>"},{"location":"api-reference/job_store/#executor.engine.manager.JobStore.values","title":"<code>values()</code>","text":"<p>Get all values(Job).</p> Source code in <code>executor/engine/manager.py</code> <pre><code>def values(self) -&gt; T.List[Job]:\n    \"\"\"Get all values(Job).\"\"\"\n    vals = list(self.mem.values())\n    return vals\n</code></pre>"},{"location":"api-reference/launcher/","title":"Launcher","text":""},{"location":"api-reference/launcher/#executor.engine.launcher.core.launcher","title":"<code>executor.engine.launcher.core.launcher(func=None, engine=None, async_mode=False, job_type='process', name=None, description=None, tags=None, job_attrs=None)</code>","text":"<p>Create a launcher for a function.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Optional[Union[Callable, Cmd2Func]]</code> <p>The function to be launched. If the function is instance of Cmd2Func, the launcher will be in subprocess mode, will launch <code>SubprocessJob</code> on each submit.</p> <code>None</code> <code>engine</code> <code>Optional[Engine]</code> <p>The engine to use. If not specified, the default engine will be used.</p> <code>None</code> <code>async_mode</code> <code>bool</code> <p>If True, the launcher will be AsyncLauncher.</p> <code>False</code> <code>job_type</code> <code>JOB_TYPES</code> <p>The job type to use. Default is 'process'.</p> <code>'process'</code> <code>name</code> <code>Optional[str]</code> <p>The name of the launcher.</p> <code>None</code> <code>description</code> <code>Optional[str]</code> <p>The description of the launcher.</p> <code>None</code> <code>tags</code> <code>Optional[List[str]]</code> <p>The tags of the launcher.</p> <code>None</code> <code>job_attrs</code> <code>Optional[dict]</code> <p>The attributes for creating the job.</p> <code>None</code> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def launcher(\n        func: T.Optional[T.Union[T.Callable, Cmd2Func]] = None,\n        engine: T.Optional['Engine'] = None,\n        async_mode: bool = False,\n        job_type: JOB_TYPES = 'process',\n        name: T.Optional[str] = None,\n        description: T.Optional[str] = None,\n        tags: T.Optional[T.List[str]] = None,\n        job_attrs: T.Optional[dict] = None):\n    \"\"\"Create a launcher for a function.\n\n    Args:\n        func: The function to be launched. If the function is instance of\n            [Cmd2Func](https://github.com/Nanguage/cmd2func),\n            the launcher will be in subprocess mode,\n            will launch `SubprocessJob` on each submit.\n        engine: The engine to use. If not specified, the default engine\n            will be used.\n        async_mode: If True, the launcher will be AsyncLauncher.\n        job_type: The job type to use. Default is 'process'.\n        name: The name of the launcher.\n        description: The description of the launcher.\n        tags: The tags of the launcher.\n        job_attrs: The attributes for creating the job.\n    \"\"\"\n    if func is None:\n        return functools.partial(\n            launcher, engine=engine, async_mode=async_mode,\n            job_type=job_type, name=name,\n            description=description, tags=tags,\n            job_attrs=job_attrs\n        )\n\n    launcher_cls: T.Union[T.Type[AsyncLauncher], T.Type[SyncLauncher]]\n    if async_mode:\n        launcher_cls = AsyncLauncher\n    else:\n        launcher_cls = SyncLauncher\n\n    return launcher_cls(\n        func, engine, job_type,\n        name, description, tags, job_attrs,\n    )\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.LauncherBase","title":"<code>executor.engine.launcher.core.LauncherBase</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>class LauncherBase(object):\n    def __init__(\n            self, target_func: T.Union[T.Callable, Cmd2Func],\n            engine: T.Optional['Engine'] = None,\n            job_type: JOB_TYPES = 'process',\n            name: T.Optional[str] = None,\n            description: T.Optional[str] = None,\n            tags: T.Optional[T.List[str]] = None,\n            job_attrs: T.Optional[dict] = None,):\n        self._engine = engine\n        self.target_func = target_func\n        self.__signature__ = inspect.signature(target_func)\n        self.job_type = job_type\n        if isinstance(target_func, Cmd2Func):\n            if self.job_type != 'webapp':\n                self.job_type = 'subprocess'\n        self.desc = parse_func(target_func)\n        self.name = name or get_callable_name(target_func)\n        self.description = description or self.target_func.__doc__\n        functools.update_wrapper(self, target_func)\n        self.tags = tags or []\n        job_attrs = job_attrs or {}\n        self.job_attrs = job_attrs\n        self.job_attrs.update({\n            'name': self.name,\n        })\n\n    @property\n    def engine(self) -&gt; Engine:\n        \"\"\"Get the engine of the launcher.\"\"\"\n        if self._engine is None:\n            self._engine = get_default_engine()\n        return self._engine\n\n    @engine.setter\n    def engine(self, engine: Engine):\n        \"\"\"Set the engine of the launcher.\"\"\"\n        self._engine = engine\n\n    def create_job(self, args: tuple, kwargs: dict, **attrs) -&gt; 'Job':\n        \"\"\"Create a job from the launcher.\"\"\"\n        job_attrs = copy(self.job_attrs)\n        job_attrs.update(attrs)\n        job_class = job_type_classes[self.job_type]\n        if isinstance(self.target_func, Cmd2Func):\n            assert job_class in (SubprocessJob, WebappJob)\n            cmd_or_gen = self.target_func.get_cmd_str(*args, **kwargs)\n            if isinstance(cmd_or_gen, str):\n                cmd = cmd_or_gen\n            else:\n                cmd = next(cmd_or_gen)\n            job = job_class(cmd, **job_attrs)  # type: ignore\n        else:\n            if job_class is WebappJob:\n                kwargs = copy(kwargs)\n                kwargs.update(job_attrs)\n                job = job_class(self.target_func, *args, **kwargs)\n            else:\n                job = job_class(\n                    self.target_func, args, kwargs,\n                    **job_attrs\n                )\n        return job\n\n    @staticmethod\n    def _fetch_result(job: 'Job') -&gt; T.Any:\n        if job.status == \"failed\":\n            raise job.exception()\n        elif job.status == \"cancelled\":\n            raise RuntimeError(\"Job cancelled\")\n        else:\n            return job.result()\n\n    def __call__(\n            self, *args: T.Any, **kwargs: T.Any) -&gt; T.Any:  # pragma: no cover\n        raise NotImplementedError(\"Subclasses must implement __call__\")\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.LauncherBase.engine","title":"<code>engine</code>  <code>property</code> <code>writable</code>","text":"<p>Get the engine of the launcher.</p>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.LauncherBase.create_job","title":"<code>create_job(args, kwargs, **attrs)</code>","text":"<p>Create a job from the launcher.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def create_job(self, args: tuple, kwargs: dict, **attrs) -&gt; 'Job':\n    \"\"\"Create a job from the launcher.\"\"\"\n    job_attrs = copy(self.job_attrs)\n    job_attrs.update(attrs)\n    job_class = job_type_classes[self.job_type]\n    if isinstance(self.target_func, Cmd2Func):\n        assert job_class in (SubprocessJob, WebappJob)\n        cmd_or_gen = self.target_func.get_cmd_str(*args, **kwargs)\n        if isinstance(cmd_or_gen, str):\n            cmd = cmd_or_gen\n        else:\n            cmd = next(cmd_or_gen)\n        job = job_class(cmd, **job_attrs)  # type: ignore\n    else:\n        if job_class is WebappJob:\n            kwargs = copy(kwargs)\n            kwargs.update(job_attrs)\n            job = job_class(self.target_func, *args, **kwargs)\n        else:\n            job = job_class(\n                self.target_func, args, kwargs,\n                **job_attrs\n            )\n    return job\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.SyncLauncher","title":"<code>executor.engine.launcher.core.SyncLauncher</code>","text":"<p>               Bases: <code>LauncherBase</code></p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>class SyncLauncher(LauncherBase):\n\n    @property\n    def async_mode(self):\n        \"\"\"Check if the launcher is in async mode.\"\"\"\n        return False\n\n    def submit(self, *args, **kwargs) -&gt; Job:\n        \"\"\"Submit a job to the engine.\"\"\"\n        job = self.create_job(args, kwargs)\n        self.engine.submit(job)\n        return job\n\n    def __call__(self, *args, **kwargs) -&gt; T.Any:\n        \"\"\"Submit a job to the engine and wait for the result.\"\"\"\n        job = self.submit(*args, **kwargs)\n        self.engine.wait_job(job)\n        return self._fetch_result(job)\n\n    def to_async(self) -&gt; \"AsyncLauncher\":\n        \"\"\"Convert the launcher to async mode.\"\"\"\n        return AsyncLauncher(\n            self.target_func, self._engine, self.job_type,\n            self.name, self.description, self.tags,\n            job_attrs=self.job_attrs,\n        )\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.SyncLauncher.async_mode","title":"<code>async_mode</code>  <code>property</code>","text":"<p>Check if the launcher is in async mode.</p>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.SyncLauncher.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Submit a job to the engine and wait for the result.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def __call__(self, *args, **kwargs) -&gt; T.Any:\n    \"\"\"Submit a job to the engine and wait for the result.\"\"\"\n    job = self.submit(*args, **kwargs)\n    self.engine.wait_job(job)\n    return self._fetch_result(job)\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.SyncLauncher.submit","title":"<code>submit(*args, **kwargs)</code>","text":"<p>Submit a job to the engine.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def submit(self, *args, **kwargs) -&gt; Job:\n    \"\"\"Submit a job to the engine.\"\"\"\n    job = self.create_job(args, kwargs)\n    self.engine.submit(job)\n    return job\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.SyncLauncher.to_async","title":"<code>to_async()</code>","text":"<p>Convert the launcher to async mode.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def to_async(self) -&gt; \"AsyncLauncher\":\n    \"\"\"Convert the launcher to async mode.\"\"\"\n    return AsyncLauncher(\n        self.target_func, self._engine, self.job_type,\n        self.name, self.description, self.tags,\n        job_attrs=self.job_attrs,\n    )\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.AsyncLauncher","title":"<code>executor.engine.launcher.core.AsyncLauncher</code>","text":"<p>               Bases: <code>LauncherBase</code></p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>class AsyncLauncher(LauncherBase):\n    @property\n    def async_mode(self):\n        \"\"\"Check if the launcher is in async mode.\"\"\"\n        return True\n\n    async def submit(self, *args, **kwargs):\n        \"\"\"Submit a job to the engine.\"\"\"\n        job = self.create_job(args, kwargs)\n        await self.engine.submit_async(job)\n        return job\n\n    async def __call__(self, *args, **kwargs) -&gt; T.Any:\n        \"\"\"Submit a job to the engine and wait for the result.\"\"\"\n        job = await self.submit(*args, **kwargs)\n        await job.join()\n        return self._fetch_result(job)\n\n    def to_sync(self) -&gt; \"SyncLauncher\":\n        \"\"\"Convert the launcher to sync mode.\"\"\"\n        return SyncLauncher(\n            self.target_func, self._engine, self.job_type,\n            self.name, self.description, self.tags,\n            job_attrs=self.job_attrs,\n        )\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.AsyncLauncher.async_mode","title":"<code>async_mode</code>  <code>property</code>","text":"<p>Check if the launcher is in async mode.</p>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.AsyncLauncher.__call__","title":"<code>__call__(*args, **kwargs)</code>  <code>async</code>","text":"<p>Submit a job to the engine and wait for the result.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>async def __call__(self, *args, **kwargs) -&gt; T.Any:\n    \"\"\"Submit a job to the engine and wait for the result.\"\"\"\n    job = await self.submit(*args, **kwargs)\n    await job.join()\n    return self._fetch_result(job)\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.AsyncLauncher.submit","title":"<code>submit(*args, **kwargs)</code>  <code>async</code>","text":"<p>Submit a job to the engine.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>async def submit(self, *args, **kwargs):\n    \"\"\"Submit a job to the engine.\"\"\"\n    job = self.create_job(args, kwargs)\n    await self.engine.submit_async(job)\n    return job\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.AsyncLauncher.to_sync","title":"<code>to_sync()</code>","text":"<p>Convert the launcher to sync mode.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def to_sync(self) -&gt; \"SyncLauncher\":\n    \"\"\"Convert the launcher to sync mode.\"\"\"\n    return SyncLauncher(\n        self.target_func, self._engine, self.job_type,\n        self.name, self.description, self.tags,\n        job_attrs=self.job_attrs,\n    )\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.get_default_engine","title":"<code>executor.engine.launcher.core.get_default_engine()</code>","text":"<p>Get the default engine.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def get_default_engine() -&gt; Engine:\n    \"\"\"Get the default engine.\"\"\"\n    global _engine\n    if _engine is None:\n        _engine = Engine()\n    return _engine\n</code></pre>"},{"location":"api-reference/launcher/#executor.engine.launcher.core.set_default_engine","title":"<code>executor.engine.launcher.core.set_default_engine(engine)</code>","text":"<p>Set the default engine.</p> Source code in <code>executor/engine/launcher/core.py</code> <pre><code>def set_default_engine(engine: Engine):\n    \"\"\"Set the default engine.\"\"\"\n    global _engine\n    _engine = engine\n</code></pre>"}]}